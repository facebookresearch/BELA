{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff95f192-5b1e-4caf-a5cc-3290b0aebf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a100-st-p4d24xlarge-68\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from itertools import islice\n",
    "import yaml\n",
    "from hydra.experimental import compose, initialize_config_module\n",
    "import hydra\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import faiss\n",
    "import logging\n",
    "from collections import defaultdict, Counter\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "from bela.utils.analysis_utils import convert_jsonl_data_to_samples\n",
    "from bela.transforms.spm_transform import SPMTransform\n",
    "from bela.evaluation.model_eval import ModelEval, load_file\n",
    "from bela.utils.prediction_utils import get_predictions_using_windows\n",
    "from bela.utils.analysis_utils import Entity, Sample, convert_jsonl_data_and_predictions_to_samples\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "!cat /etc/hostname  # Double check that we are on a gpu node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f8f2dc7",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf93bf95-295e-4efd-8133-bd9aedf156d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         34358726 function calls (34319027 primitive calls) in 55.779 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 1807 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3   15.804    5.268   15.804    5.268 serialization.py:994(load_tensor)\n",
      "        1   13.157   13.157   13.157   13.157 {built-in method faiss._swigfaiss.GpuIndexFlat_add}\n",
      "        1   12.731   12.731   14.152   14.152 joint_el_datamodule.py:21(__init__)\n",
      "        1    2.868    2.868   55.780   55.780 <string>:2(<module>)\n",
      "        1    1.954    1.954   52.912   52.912 model_eval.py:31(__init__)\n",
      "      302    1.849    0.006    1.849    0.006 {method 'uniform_' of 'torch._C._TensorBase' objects}\n",
      "        4    1.847    0.462    1.847    0.462 {method 'normal_' of 'torch._C._TensorBase' objects}\n",
      " 16470920    1.372    0.000    1.372    0.000 {method 'strip' of 'str' objects}\n",
      "      396    1.028    0.003    1.028    0.003 {method '_set_from_file' of 'torch._C.StorageBase' objects}\n",
      " 16496765    0.829    0.000    0.829    0.000 {method 'append' of 'list' objects}"
     ]
    }
   ],
   "source": [
    "%%prun -s tottime -l 10\n",
    "\n",
    "# e2e model with isotropic embeddings\n",
    "checkpoint_path = '/checkpoints/movb/bela/2023-01-13-023711/0/lightning_logs/version_4144/checkpoints/last.ckpt'  # Not working: Unexpected key(s) in state_dict: \"saliency_encoder.mlp.0.weight\", \"saliency_encoder.mlp.0.bias\", \"saliency_encoder.mlp.3.weight\", \"saliency_encoder.mlp.3.bias\", \"saliency_encoder.mlp.6.weight\", \"saliency_encoder.mlp.6.bias\". \n",
    "checkpoint_path = '/checkpoints/movb/bela/2022-11-27-225013/0/lightning_logs/version_286287/checkpoints/last_15000.ckpt'  # Works but 0 F1\n",
    "\n",
    "# E2E checkpoint with new embeddings\n",
    "# https://fb.quip.com/QVUxA4UcAZ7k#temp:C:OcG977f71fab43d42379521a0dff\n",
    "# Works but give 0 F1 on tackbp (mention detection is okish, but entity disambiguation is random)\n",
    "checkpoint_path = '/checkpoints/movb/bela/2023-01-18-220105/0/lightning_logs/version_4820/checkpoints/last.ckpt'  \n",
    "# Overfit on one sample from /fsx/louismartin/bela/data/debug_mention_detection/mel/train.1st.1_sample.txt\n",
    "checkpoint_path = '/data/home/louismartin/dev/BELA/multirun/2023-02-14/08-45-13/0/lightning_logs/version_0/checkpoints/checkpoint_best.ckpt'\n",
    "checkpoint_path = \"/data/home/louismartin/dev/BELA/multirun/2023-02-15/15-59-33/0/lightning_logs/version_0/checkpoints/checkpoint_best.ckpt\"\n",
    "checkpoint_path = \"/data/home/louismartin/dev/BELA/multirun/2023-02-15/16-16-51/0/lightning_logs/version_0/checkpoints/checkpoint_best-v1.ckpt\"\n",
    "# Overfit on 100 samples (.948 f1\n",
    "checkpoint_path = \"/data/home/louismartin/dev/BELA/multirun/2023-02-15/23-28-57/0/lightning_logs/version_0/checkpoints/checkpoint_best.ckpt\"\n",
    "checkpoint_path = \"/checkpoints/movb/bela/2023-02-15-200343/0/lightning_logs/version_127953/checkpoints/checkpoint_4.ckpt\"\n",
    "# New fixed checkpoint\n",
    "checkpoint_path = \"/checkpoints/movb/bela/2023-02-15-200343/0/lightning_logs/version_127953/checkpoints/checkpoint_best-v2.ckpt\"\n",
    "# Finetuned on TACKBP\n",
    "#checkpoint_path = \"/data/home/louismartin/dev/BELA/multirun/2023-02-17/00-08-45/0/lightning_logs/version_0/checkpoints/checkpoint_best.ckpt\"\n",
    "checkpoint_path = \"/data/home/louismartin/dev/BELA/multirun/2023-02-17/00-08-45/0/lightning_logs/version_0/checkpoints/checkpoint_best-v2.ckpt\"\n",
    "# Finetuned on TACKBP (shuffled data)\n",
    "checkpoint_path = \"/checkpoints/louismartin/bela/2023-02-17-193248/lightning_logs/version_0/checkpoints/checkpoint_best-v1.ckpt\"\n",
    "## Finetuned on pseudo-labeled data / silver data\n",
    "#checkpoint_path = \"/checkpoints/movb/bela/2023-02-17-172049/lightning_logs/version_0/checkpoints/checkpoint_2.ckpt\"\n",
    "# Finetuned on aida\n",
    "checkpoint_path = \"/checkpoints/movb/bela/aida/lightning_logs/version_0/checkpoints/checkpoint_1.ckpt\"\n",
    "model_eval = ModelEval(checkpoint_path, config_name=\"joint_el_mel_new_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ca00ed",
   "metadata": {},
   "source": [
    "# End-to-end Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "000fd83c-fd03-4e8a-a3da-d8df70477d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_eval.checkpoint_path='/checkpoints/movb/bela/aida/lightning_logs/version_0/checkpoints/checkpoint_1.ckpt'\n",
      "model_eval.task.md_threshold=0\n",
      "model_eval.task.el_threshold=0\n",
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_spa.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:00, 19367.60it/s]\n",
      " 50%|█████████████████████▌                     | 1/2 [01:04<01:04, 64.61s/it]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "﻿E != El",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m test_data \u001b[39m=\u001b[39m load_file(test_data_path)\n\u001b[1;32m     30\u001b[0m \u001b[39m#print(\"Loading only 100 samples for debugging\")\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m#test_data = test_data[:100]\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m predictions \u001b[39m=\u001b[39m get_predictions_using_windows(model_eval, test_data, window_length\u001b[39m=\u001b[39;49m\u001b[39m254\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m \u001b[39m#predictions = model_eval.get_predictions(test_data)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m (f1, precision, recall), (f1_boe, precision_boe, recall_boe) \u001b[39m=\u001b[39m ModelEval\u001b[39m.\u001b[39mcompute_scores(test_data, predictions)\n",
      "File \u001b[0;32m~/dev/BELA/bela/utils/prediction_utils.py:151\u001b[0m, in \u001b[0;36mget_predictions_using_windows\u001b[0;34m(model_eval, test_data, batch_size, window_length, window_overlap)\u001b[0m\n\u001b[1;32m    139\u001b[0m         new_text \u001b[39m=\u001b[39m text[start_pos:end_pos]\n\u001b[1;32m    140\u001b[0m         extended_examples\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    141\u001b[0m             {\n\u001b[1;32m    142\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mdocument_id\u001b[39m\u001b[39m\"\u001b[39m: document_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m             }\n\u001b[1;32m    149\u001b[0m         )\n\u001b[0;32m--> 151\u001b[0m all_predictions \u001b[39m=\u001b[39m model_eval\u001b[39m.\u001b[39;49mget_predictions(\n\u001b[1;32m    152\u001b[0m     extended_examples, batch_size\u001b[39m=\u001b[39;49mbatch_size\n\u001b[1;32m    153\u001b[0m )\n\u001b[1;32m    154\u001b[0m predictions_dict \u001b[39m=\u001b[39m group_predictions_by_example(all_predictions, extended_examples)\n\u001b[1;32m    156\u001b[0m predictions \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/dev/BELA/bela/evaluation/model_eval.py:258\u001b[0m, in \u001b[0;36mModelEval.get_predictions\u001b[0;34m(self, test_data, batch_size)\u001b[0m\n\u001b[1;32m    256\u001b[0m     batch \u001b[39m=\u001b[39m test_data[batch_start:batch_start\u001b[39m+\u001b[39mbatch_size]\n\u001b[1;32m    257\u001b[0m     texts \u001b[39m=\u001b[39m [example[\u001b[39m'\u001b[39m\u001b[39moriginal_text\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m example \u001b[39min\u001b[39;00m batch]\n\u001b[0;32m--> 258\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_batch(texts)\n\u001b[1;32m    259\u001b[0m     all_predictions\u001b[39m.\u001b[39mextend(predictions)\n\u001b[1;32m    260\u001b[0m \u001b[39mreturn\u001b[39;00m all_predictions\n",
      "File \u001b[0;32m~/dev/BELA/bela/evaluation/model_eval.py:83\u001b[0m, in \u001b[0;36mModelEval.process_batch\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_batch\u001b[39m(\u001b[39mself\u001b[39m, texts): \n\u001b[1;32m     82\u001b[0m     batch: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtexts\u001b[39m\u001b[39m\"\u001b[39m: texts}\n\u001b[0;32m---> 83\u001b[0m     model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(batch)\n\u001b[1;32m     85\u001b[0m     token_ids \u001b[39m=\u001b[39m model_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     86\u001b[0m     text_pad_mask \u001b[39m=\u001b[39m model_inputs[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/bela3.8/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/BELA/bela/transforms/joint_el_transform.py:828\u001b[0m, in \u001b[0;36mJointELXlmrRawTextTransform.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, batch: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 828\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(batch))\n",
      "File \u001b[0;32m~/dev/BELA/bela/transforms/joint_el_transform.py:749\u001b[0m, in \u001b[0;36mJointELXlmrRawTextTransform.transform\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    745\u001b[0m     texts, insertions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insert_spaces_to_texts(texts)\n\u001b[1;32m    747\u001b[0m word_boundaries \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calculate_alpha_num_boundaries(texts)\n\u001b[0;32m--> 749\u001b[0m sp_tokens_with_indices: List[List[Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mforward(texts)\n\u001b[1;32m    750\u001b[0m sp_token_ids: List[List[\u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m [\n\u001b[1;32m    751\u001b[0m     [sp_token \u001b[39mfor\u001b[39;00m sp_token, _, _ \u001b[39min\u001b[39;00m tokens] \u001b[39mfor\u001b[39;00m tokens \u001b[39min\u001b[39;00m sp_tokens_with_indices\n\u001b[1;32m    752\u001b[0m ]\n\u001b[1;32m    753\u001b[0m \u001b[39m# append bos and eos tokens\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/BELA/bela/transforms/spm_transform.py:59\u001b[0m, in \u001b[0;36mSPMTransform.forward\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     57\u001b[0m output \u001b[39m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m texts:\n\u001b[0;32m---> 59\u001b[0m     token_ids_with_offsets \u001b[39m=\u001b[39m convert_text_to_spm_tokens_with_char_offsets(text, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocessor)\n\u001b[1;32m     60\u001b[0m     \u001b[39m# Add 1 to all token ids except for the unk token\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     token_ids_with_offsets \u001b[39m=\u001b[39m [\n\u001b[1;32m     62\u001b[0m         (token_id \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m token_id \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munk_token_id, start_offset, end_offset)\n\u001b[1;32m     63\u001b[0m         \u001b[39mfor\u001b[39;00m token_id, start_offset, end_offset \u001b[39min\u001b[39;00m token_ids_with_offsets\n\u001b[1;32m     64\u001b[0m     ]\n",
      "File \u001b[0;32m~/dev/BELA/bela/transforms/spm_transform.py:22\u001b[0m, in \u001b[0;36mconvert_text_to_spm_tokens_with_char_offsets\u001b[0;34m(text, spm_processor)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m piece \u001b[39min\u001b[39;00m spt\u001b[39m.\u001b[39mpieces:\n\u001b[1;32m     18\u001b[0m     \u001b[39m# NOTE: It seems we can't use piece.begin and piece.end because it sometimes break, e.g. with\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m# `text = \"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete \"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m# At some point piece.begin will not correspond to the actual offset in the text\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     end_offset \u001b[39m=\u001b[39m start_offset \u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(piece\u001b[39m.\u001b[39msurface)\n\u001b[0;32m---> 22\u001b[0m     \u001b[39massert\u001b[39;00m text[start_offset:end_offset] \u001b[39m==\u001b[39m piece\u001b[39m.\u001b[39msurface, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtext[start_offset:end_offset]\u001b[39m}\u001b[39;00m\u001b[39m != \u001b[39m\u001b[39m{\u001b[39;00mpiece\u001b[39m.\u001b[39msurface\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m     token_ids_with_offsets\u001b[39m.\u001b[39mappend((piece\u001b[39m.\u001b[39mid, start_offset, end_offset))\n\u001b[1;32m     24\u001b[0m     start_offset \u001b[39m=\u001b[39m end_offset\n",
      "\u001b[0;31mAssertionError\u001b[0m: ﻿E != El"
     ]
    }
   ],
   "source": [
    "\n",
    "model_eval.task.md_threshold = 0\n",
    "model_eval.task.el_threshold = 0\n",
    "#model_eval.task.md_threshold = 0.2\n",
    "#model_eval.task.el_threshold = 0.4\n",
    "#model_eval.task.md_threshold = 0.1\n",
    "#model_eval.task.el_threshold = 0.1\n",
    "print(f\"{model_eval.checkpoint_path=}\")\n",
    "print(f\"{model_eval.task.md_threshold=}\")\n",
    "print(f\"{model_eval.task.el_threshold=}\")\n",
    "datasets = [\n",
    "    #\"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_all_languages.jsonl\",\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_spa.jsonl\",\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_cmn.jsonl\",\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_eng.jsonl\",\n",
    "    #\"/fsx/louismartin/bela/data/debug_mention_detection/mel/eval.1st.1_sample.txt\",  # Overfit on one sample\n",
    "    #\"/fsx/louismartin/bela/data/debug_mention_detection/100_samples/eval.txt\",  # Overfit on 100 samples\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ta.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ar.jsonl',\n",
    "    ##'/fsx/movb/data/matcha/mewsli-9/en.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/fa.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/sr.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/tr.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/de.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/es.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ja.jsonl',\n",
    "]\n",
    "for test_data_path in datasets:\n",
    "    print(f\"Processing {test_data_path}\")\n",
    "    test_data = load_file(test_data_path)\n",
    "    #print(\"Loading only 100 samples for debugging\")\n",
    "    #test_data = test_data[:100]\n",
    "    \n",
    "    predictions = get_predictions_using_windows(model_eval, test_data, window_length=256)\n",
    "    #predictions = model_eval.get_predictions(test_data)\n",
    "    (f1, precision, recall), (f1_boe, precision_boe, recall_boe) = ModelEval.compute_scores(test_data, predictions)\n",
    "    #model_results = ModelResults(test_data, predictions)\n",
    "    #(f1, precision, recall), (f1_boe, precision_boe, recall_boe) = model_results.compute_scores()\n",
    "    \n",
    "    print(f\"F1 = {f1:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\")\n",
    "    #print(f\"F1 boe = {f1_boe:.4f}, precision = {precision_boe:.4f}, recall = {recall_boe:.4f}\")\n",
    "    samples = convert_jsonl_data_and_predictions_to_samples(jsonl_data=test_data, predictions=predictions, md_threshold=model_eval.task.md_threshold, el_threshold=model_eval.task.el_threshold)\n",
    "    for sample in islice(samples, 0):\n",
    "        if len(sample.false_positives) + len(sample.false_negatives) == 0:\n",
    "            continue\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"{sample.text[500:]=}\")\n",
    "        print(f\"***************** {len(sample.true_positives)} True Positives *****************\")\n",
    "        pprint(sample.true_positives[:5])\n",
    "        print(f\"***************** {len(sample.false_positives)} False Positives *****************\")\n",
    "        pprint(sample.false_positives[:5])\n",
    "        print(f\"***************** {len(sample.false_negatives)} False Negatives *****************\")\n",
    "        pprint(sample.false_negatives[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d7f28bba",
   "metadata": {},
   "source": [
    "## Grid search for thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1628cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import product\n",
    "results = {}\n",
    "for md_threshold, el_threshold in tqdm(list(product(np.arange(0, 0.6, 0.2), repeat=2))):\n",
    "    model_eval.task.md_threshold = md_threshold\n",
    "    model_eval.task.el_threshold = el_threshold\n",
    "    print(f\"{model_eval.checkpoint_path=}\")\n",
    "    print(f\"{model_eval.task.md_threshold=}\")\n",
    "    print(f\"{model_eval.task.el_threshold=}\")\n",
    "    datasets = [\n",
    "        \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_all_languages.jsonl\",\n",
    "    ]\n",
    "    for test_data_path in datasets:\n",
    "        print(f\"Processing {test_data_path}\")\n",
    "        test_data = load_file(test_data_path)\n",
    "        #print(\"Loading only 100 samples for debugging\")\n",
    "        #test_data = test_data[:100]\n",
    "        predictions = get_predictions_using_windows(model_eval, test_data, window_length=1024)\n",
    "        (f1, precision, recall), (f1_boe, precision_boe, recall_boe) = ModelEval.compute_scores(test_data, predictions)\n",
    "        print(f\"F1 = {f1:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\")\n",
    "        print(f\"F1 boe = {f1_boe:.4f}, precision = {precision_boe:.4f}, recall = {recall_boe:.4f}\")\n",
    "        results[(md_threshold, el_threshold)] = (f1, precision, recall), (f1_boe, precision_boe, recall_boe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "19e65875",
   "metadata": {},
   "source": [
    "# Check how many of tackbp entities are in our index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e245fcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our entity index size is 16470856\n",
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_spa.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:00, 20000.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 167 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mentions: 4046\n",
      "Unique entities: 616\n",
      "Unique entities not in index: 0\n",
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_cmn.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [00:00, 462.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 166 samples\n",
      "Total mentions: 8476\n",
      "Unique entities: 783\n",
      "Unique entities not in index: 0\n",
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_eng.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:00, 5245.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 167 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mentions: 10234\n",
      "Unique entities: 1262\n",
      "Unique entities not in index: 0\n",
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_spa.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:00, 10402.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 128 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mentions: 3151\n",
      "Unique entities: 471\n",
      "Unique entities not in index: 0\n",
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_cmn.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "147it [00:00, 2554.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 147 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mentions: 10520\n",
      "Unique entities: 800\n",
      "Unique entities not in index: 0\n",
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_eng.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:00, 5683.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 168 samples\n",
      "Total mentions: 9027\n",
      "Unique entities: 1055\n",
      "Unique entities not in index: 0\n"
     ]
    }
   ],
   "source": [
    "paths = [\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_spa.jsonl\",\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_cmn.jsonl\",\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_eng.jsonl\",\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_spa.jsonl\",\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_cmn.jsonl\",\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_eng.jsonl\",\n",
    "]\n",
    "print(f\"Our entity index size is {len(model_eval.ent_idx)}\")\n",
    "for path in paths:\n",
    "    print(f\"Processing {path}\")\n",
    "    jsonl_data = load_file(path)\n",
    "    samples = convert_jsonl_data_to_samples(jsonl_data)\n",
    "    print(f\"Loaded {len(samples)} samples\")\n",
    "    counter = Counter()\n",
    "    for sample in samples:\n",
    "        counter.update([entity.entity_id for entity in sample.ground_truth_entities])\n",
    "    unique_entities = counter.keys()\n",
    "    total_mentions = sum(counter.values())\n",
    "    entities_not_in_index = [entity_id for entity_id in counter.keys() if entity_id not in model_eval.ent_idx]\n",
    "    print(f\"Total mentions: {total_mentions}\")\n",
    "    print(f\"Unique entities: {len(unique_entities)}\")\n",
    "    print(f\"Unique entities not in index: {len(entities_not_in_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88fa2eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12522"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4046 + 8476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87075ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "167+166"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da72624",
   "metadata": {},
   "source": [
    "# Disambiguation Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shift_shift(text):\n",
    "    for idx,ch in enumerate(text):\n",
    "        if not ch.isalpha():\n",
    "            return idx\n",
    "\n",
    "def convert_data_for_disambiguation(data, lang):\n",
    "    # convert examples to 1 entity per example and shift if needed\n",
    "    if lang=='ar':\n",
    "        MAX_LENGTH = 600\n",
    "        MAX_OFFSET = 400\n",
    "    elif lang == 'ja':\n",
    "        MAX_LENGTH = 350\n",
    "        MAX_OFFSET = 250\n",
    "    else:\n",
    "        MAX_LENGTH = 800\n",
    "        MAX_OFFSET = 600\n",
    "    new_examples = []\n",
    "    for example in tqdm(data):\n",
    "        original_text = example['original_text']\n",
    "        for _, _, ent, _, offset, length in example['gt_entities']:\n",
    "            shift = 0\n",
    "            if len(original_text) > MAX_LENGTH and offset > MAX_OFFSET:\n",
    "                shift = (offset - MAX_OFFSET)\n",
    "                shift += shift_shift(original_text[shift:])\n",
    "            new_example = {\n",
    "                'original_text': original_text[shift:],\n",
    "                'gt_entities': [[0,0,ent,_,offset-shift,length]],\n",
    "            }\n",
    "            new_examples.append(new_example)\n",
    "    return new_examples\n",
    "\n",
    "\n",
    "def metrics_disambiguation(test_data, predictions):\n",
    "    support = 0\n",
    "    support_only_predicted = 0\n",
    "    correct = 0\n",
    "    incorrect_pos = 0\n",
    "\n",
    "    for example_idx, (example, prediction) in tqdm(enumerate(zip(test_data, predictions))):\n",
    "#         targets = {\n",
    "#             (offset,length):ent_id\n",
    "#             for _,_,ent_id,_,offset,length in example['gt_entities']\n",
    "#         }\n",
    "#         prediction = {\n",
    "#             (offset,length):ent_id\n",
    "#             for offset,length,ent_id in zip(prediction['offsets'], prediction['lengths'], prediction['entities'])\n",
    "#         }\n",
    "\n",
    "#         support += len(targets)\n",
    "#         support_only_predicted += len(prediction)\n",
    "        \n",
    "#         correct += sum(1 for pos,ent_id in prediction.items() if (pos in targets and targets[pos] == ent_id))\n",
    "#         incorrect_pos += sum(1 for pos,_ in prediction.items() if pos not in targets)\n",
    "        if len(prediction['entities']) == 0:\n",
    "            continue\n",
    "        target = example['gt_entities'][0][2]\n",
    "        prediction = prediction['entities'][0]\n",
    "        correct += (target == prediction)\n",
    "        support += 1\n",
    "\n",
    "    accuracy = correct/support\n",
    "    # accuracy_only_predicted = correct/support_only_predicted\n",
    "\n",
    "    return accuracy, support #, accuracy_only_predicted, support_only_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ta.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ar.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/en.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/fa.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/sr.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/tr.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/de.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/es.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ja.jsonl',\n",
    "]\n",
    "for test_data_path in datasets:\n",
    "    print(f\"Processing {test_data_path}\")\n",
    "    lang = test_data_path[-8:-6]\n",
    "    test_data = load_file(test_data_path)\n",
    "    test_data = convert_data_for_disambiguation(test_data[:10000], lang)\n",
    "    predictions = model_eval.get_disambiguation_predictions(test_data)\n",
    "    accuracy, support = metrics_disambiguation(test_data, predictions)\n",
    "    print(f\"Accuracty {accuracy}, support {support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e49a90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bela.transforms.spm_transform import *\n",
    "len(convert_text_to_spm_tokens_with_char_offsets(line[\"original_text\"], model_eval.transform.processor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cae751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1270it [00:00, 17120.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def yield_jsonl_lines(path):\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "\n",
    "\n",
    "path = Path(\"/fsx/movb/data/matcha/mel/train.1st.txt\")\n",
    "train_path = Path(\"/fsx/louismartin/bela/data/debug_mention_detection/100_samples/train.txt\")\n",
    "i = 0\n",
    "lines = []\n",
    "for line in tqdm(yield_jsonl_lines(path)):\n",
    "    if not \"is a\" in line['original_text']:\n",
    "        continue\n",
    "    #if len(line[\"original_text\"]) > 256 * 4:\n",
    "    #    continue\n",
    "    if len(convert_text_to_spm_tokens_with_char_offsets(line[\"original_text\"], model_eval.transform.processor)) > 256 * 0.9:\n",
    "        continue\n",
    "    lines.append(line)\n",
    "    i += 1\n",
    "    if i >= 100:\n",
    "        break\n",
    "# Write lines 1000 times in a file\n",
    "with open(train_path, \"w\") as f:\n",
    "    for _ in range(1000):\n",
    "        for line in lines:\n",
    "            f.write(json.dumps(line) + \"\\n\")\n",
    "eval_path = Path(\"/fsx/louismartin/bela/data/debug_mention_detection/100_samples/eval.txt\")\n",
    "with open(eval_path, \"w\") as f:\n",
    "    for line in lines:\n",
    "        f.write(json.dumps(line) + \"\\n\")\n",
    "test_path = Path(\"/fsx/louismartin/bela/data/debug_mention_detection/100_samples/test.txt\")\n",
    "with open(test_path, \"w\") as f:\n",
    "    for line in lines:\n",
    "        f.write(json.dumps(line) + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eff17084",
   "metadata": {},
   "source": [
    "## Eyeball Samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "871973a2",
   "metadata": {},
   "source": [
    "With text directly as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced14ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.text[:max_display_length]=\"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany. She competed in the 800 metres and occasionally the 400 metres.  Her first success came at the 1977 European Athletics Junior Championships, where she won the 800 m title. At twenty years old, reached the final at the 1980 Moscow Olympics and placed fourth in a lifetime best time of 1:56.21 behind a Soviet trio of Nadiya Olizarenko, Olga Mineyeva and Tatyana Providokhina that broke the world record. A successful 1981 season followed, which included a win at the 1981 European Cup, and at the 1981 IAAF World Cup she won an 800 m silver behind Lyudmila Veselkova and a gold with the East German 4 × 400 metres relay team. She ranked second in the world that year for the 800 m behind Vesselkova with a time of 1:57.16. That success continued into 1982 with a silver medal at the 1982 European Athletics Indoor Championships, finishing second only to Romania's Doina Mel\"\n",
      "***************** Predicted entities *****************\n",
      "len(self.predicted_entities)=16\n",
      "Entity<mention=\" track and\", entity_id=Q3312129, md_score=0.98, el_score=1.00>\n",
      "Entity<mention=\" East\", entity_id=Q16957, md_score=0.98, el_score=1.00>\n",
      "Entity<mention=\" 800\", entity_id=Q271008, md_score=0.99, el_score=1.00>\n",
      "Entity<mention=\" 400\", entity_id=Q334734, md_score=0.99, el_score=1.00>\n",
      "Entity<mention=\" 1977 European Athletics Junior Championship\", entity_id=Q974310, md_score=0.96, el_score=1.00>\n",
      "Entity<mention=\" 1980 Moscow Olympic\", entity_id=Q8450, md_score=0.97, el_score=1.00>\n",
      "Entity<mention=\" Nadiya Olizar\", entity_id=Q231445, md_score=0.94, el_score=1.00>\n",
      "Entity<mention=\" Olga Mineyev\", entity_id=Q452613, md_score=0.95, el_score=1.00>\n",
      "Entity<mention=\" Tatyana Providok\", entity_id=Q452678, md_score=0.95, el_score=1.00>\n",
      "Entity<mention=\" 1981\", entity_id=Q4580115, md_score=0.98, el_score=1.00>\n",
      "Entity<mention=\" 1981 European\", entity_id=Q2999663, md_score=0.98, el_score=1.00>\n",
      "Entity<mention=\" 1981 IAAF World\", entity_id=Q1814515, md_score=0.97, el_score=1.00>\n",
      "Entity<mention=\" Lyudmila Vesel\", entity_id=Q6710553, md_score=0.97, el_score=1.00>\n",
      "Entity<mention=\" 4 × 400 metres rela\", entity_id=Q230057, md_score=0.97, el_score=1.00>\n",
      "Entity<mention=\" 1982 European Athletics Indoor Championship\", entity_id=Q265197, md_score=0.96, el_score=1.00>\n",
      "Entity<mention=\" Doina Mel\", entity_id=Q237005, md_score=0.97, el_score=1.00>\n"
     ]
    }
   ],
   "source": [
    "from bela.evaluation.model_eval import Sample\n",
    "text = \"Her name is Taylor Swift. New York City is a city in the United States.\"\n",
    "text = \"My dog is a Shiba Inu. Taylor Swift is a singer.\"\n",
    "text = \"Her name is Taylor Swift.\"\n",
    "text = \"He is the Dalai Lama. He is a Buddhist monk.\"\n",
    "text = \"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany. She competed in the 800 metres and occasionally the 400 metres.  Her first success came at the 1977 European Athletics Junior Championships, where she won the 800 m title. At twenty years old, reached the final at the 1980 Moscow Olympics and placed fourth in a lifetime best time of 1:56.21 behind a Soviet trio of Nadiya Olizarenko, Olga Mineyeva and Tatyana Providokhina that broke the world record. A successful 1981 season followed, which included a win at the 1981 European Cup, and at the 1981 IAAF World Cup she won an 800 m silver behind Lyudmila Veselkova and a gold with the East German 4 × 400 metres relay team. She ranked second in the world that year for the 800 m behind Vesselkova with a time of 1:57.16. That success continued into 1982 with a silver medal at the 1982 European Athletics Indoor Championships, finishing second only to Romania's Doina Melinte. She was top of the world indoor rankings that season with 1:59.24 minutes.  She was a three-time national champion, winning the 800 m at the East German Athletics Championships in 1981 before taking a national indoor and outdoor double in 1982.  She holds one of the fastest times for the 1000 metres at 2:30.85 minutes. This was the second fastest ever when it was set in 1980, behind Soviet runner Tatyana Providokhina, though it remained the fastest recorded electronically recorded time for ten years. It remains the best mark by an under-23 athlete and she also holds the under-23 best for the 600 metres event with 1:24.56 minutes.  Steuk was born in Berlin and was a member of her local club Berliner TSC. She married East German hammer thrower Roland Steuk in 1991. The two subsequently divorced. She was awarded the Patriotic Order of Merit for her athletic feats in 1982. \"\n",
    "prediction = model_eval.process_batch([text])[0]\n",
    "predicted_entities = [Entity(offset=offset, length=length, text=text, entity_id=entity_id, md_score=md_score, el_score=el_score) for offset, length, entity_id, md_score, el_score in zip(prediction[\"offsets\"], prediction[\"lengths\"], prediction[\"entities\"], prediction[\"md_scores\"], prediction[\"el_scores\"])]\n",
    "Sample(text=text, predicted_entities=predicted_entities).print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e95d1d34",
   "metadata": {},
   "source": [
    "From file with windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a77ac96a-b29e-45c3-9ab1-43ddcd387572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /fsx/louismartin/bela/data/debug_mention_detection/mel/eval.1st.1_sample.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:00, 22171.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁track', '▁and', '▁field']\n",
      "\n",
      "['▁East', '▁Germany', '.']\n",
      "\n",
      "['▁metres']\n",
      "\n",
      "['▁metres', '.']\n",
      "\n",
      "['▁1977', '▁European', '▁Athletic', 's', '▁Junior', '▁Championship', 's', ',']\n",
      "\n",
      "['▁1980', '▁Moscow', '▁Olympic', 's']\n",
      "\n",
      "['diya', '▁O', 'lizar', 'enko', ',']\n",
      "\n",
      "['diya', '▁O', 'lizar', 'enko', ',', '▁Olga', '▁Mine', 'yev', 'a']\n",
      "\n",
      "['▁Olga', '▁Mine', 'yev', 'a']\n",
      "\n",
      "['yana', '▁Pro', 'vid', 'ok', 'hina']\n",
      "\n",
      "['▁1981', '▁season']\n",
      "\n",
      "['▁1981', '▁European', '▁Cup', ',']\n",
      "\n",
      "['▁1981', '▁I', 'A', 'AF', '▁World', '▁Cup']\n",
      "\n",
      "['ud', 'mila', '▁Vesel', 'kova']\n",
      "\n",
      "['▁400', '▁metres', '▁rela', 'y']\n",
      "\n",
      "['▁1982', '▁European', '▁Athletic', 's', '▁In', 'door', '▁Championship', 's', ',']\n",
      "\n",
      "['ina', '▁Mel', 'inte', '.']\n",
      "\n",
      "text[:max_display_length]=\"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany. She competed in the 800 metres and occasionally the 400 metres.  Her first success came at the 1977 European Athletics Junior Championships, where she won the 800 m title. At twenty years old, reached the final at the 1980 Moscow Olympics and placed fourth in a lifetime best time of 1:56.21 behind a Soviet trio of Nadiya Olizarenko, Olga Mineyeva and Tatyana Providokhina that broke the world record. A successful 1981 season followed, which included a win at the 1981 European Cup, and at the 1981 IAAF World Cup she won an 800 m silver behind Lyudmila Veselkova and a gold with the East German 4 × 400 metres relay team. She ranked second in the world that year for the 800 m behind Vesselkova with a time of 1:57.16. That success continued into 1982 with a silver medal at the 1982 European Athletics Indoor Championships, finishing second only to Romania's Doina Melinte. She was top of the world indoor rankings that season with 1:59.24 minutes.  She was a three-time national champion, winning the 800 m at the East German Athletics Championships in 1981 before taking a national indoor and outdoor double in 1982.  She holds one of the fastest times for the 1000 metres at 2:30.85 minutes. This was the second fastest ever when it was set in 1980, behind Soviet runner Tatyana Providokhina, though it remained the fastest recorded electronically recorded time for ten years. It remains the best mark by an under-23 athlete and she also holds the under-23 best for the 600 metres event with 1:24.56 minutes.  Steuk was born in Berlin and was a member of her local club Berliner TSC. She married East German hammer thrower Roland Steuk in 1991. The two subsequently divorced. She was awarded the Patriotic Order of Merit for her athletic feats in 1982. \"\n",
      "***************** Ground truth entities *****************\n",
      "len(ground_truth_entities)=24\n",
      "mention=\"track and field\" -> entity_id=Q3312129\n",
      "mention=\"East Germany\" -> entity_id=Q16957\n",
      "mention=\"800 metres\" -> entity_id=Q271008\n",
      "mention=\"400 metres\" -> entity_id=Q334734\n",
      "mention=\"1977 European Athletics Junior Championships\" -> entity_id=Q974310\n",
      "mention=\"1980 Moscow Olympics\" -> entity_id=Q8450\n",
      "mention=\"Nadiya Olizarenko\" -> entity_id=Q231445\n",
      "mention=\"Olga Mineyeva\" -> entity_id=Q452613\n",
      "mention=\"Tatyana Providokhina\" -> entity_id=Q452678\n",
      "mention=\"1981 season\" -> entity_id=Q4580115\n",
      "mention=\"1981 European Cup\" -> entity_id=Q2999663\n",
      "mention=\"1981 IAAF World Cup\" -> entity_id=Q1814515\n",
      "mention=\"Lyudmila Veselkova\" -> entity_id=Q6710553\n",
      "mention=\"4 × 400 metres relay\" -> entity_id=Q230057\n",
      "mention=\"1982 European Athletics Indoor Championships\" -> entity_id=Q265197\n",
      "mention=\"Doina Melinte\" -> entity_id=Q237005\n",
      "mention=\"East German Athletics Championships\" -> entity_id=Q55610396\n",
      "mention=\"1000 metres\" -> entity_id=Q1629556\n",
      "mention=\"Tatyana Providokhina\" -> entity_id=Q452678\n",
      "mention=\"under-23 athlete\" -> entity_id=Q14510042\n",
      "mention=\"600 metres\" -> entity_id=Q2817913\n",
      "mention=\"Berlin\" -> entity_id=Q64\n",
      "mention=\"Roland Steuk\" -> entity_id=Q319394\n",
      "mention=\"Patriotic Order of Merit\" -> entity_id=Q819570\n",
      "***************** Predicted entities *****************\n",
      "len(predicted_entities)=15\n",
      "mention=\"track and field\" -> entity_id=Q3312129 (md_score=1.00, el_score=1.00)\n",
      "mention=\"East Germany.\" -> entity_id=Q16957 (md_score=1.00, el_score=1.00)\n",
      "mention=\"metres\" -> entity_id=Q271008 (md_score=1.00, el_score=1.00)\n",
      "mention=\"metres.\" -> entity_id=Q334734 (md_score=1.00, el_score=1.00)\n",
      "mention=\" 1977 European Athletics Junior Championships\" -> entity_id=Q974310 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 1980 Moscow Olympic\" -> entity_id=Q8450 (md_score=0.99, el_score=1.00)\n",
      "mention=\"diya Olizarenko, Olga Mineyeva\" -> entity_id=Q55733 (md_score=0.58, el_score=0.00)\n",
      "mention=\"yana Providokhina\" -> entity_id=Q452613 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 1981 seaso\" -> entity_id=Q452678 (md_score=1.00, el_score=1.00)\n",
      "mention=\" 1981 European Cup\" -> entity_id=Q4580115 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 1981 IAAF World Cu\" -> entity_id=Q2999663 (md_score=0.99, el_score=1.00)\n",
      "mention=\"udmila Veselkova\" -> entity_id=Q1814515 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 400 metres rela\" -> entity_id=Q6710553 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 1982 European Athletics Indoor Championships\" -> entity_id=Q230057 (md_score=0.99, el_score=1.00)\n",
      "mention=\"ina Melinte.\" -> entity_id=Q265197 (md_score=0.99, el_score=1.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_path = \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format.jsonl\"\n",
    "test_data_path = \"/fsx/louismartin/bela/data/debug_mention_detection/mel/eval.1st.1_sample.txt\"  # Overfit on one sample\n",
    "print(f\"Processing {test_data_path}\")\n",
    "test_data = load_file(test_data_path)\n",
    "#sample = test_data[200]\n",
    "sample = test_data[0]\n",
    "prediction = get_predictions_using_windows(model_eval, [sample], window_length=1024)[0]\n",
    "text = sample[\"original_text\"]\n",
    "max_length = 1024\n",
    "\n",
    "ground_truth_entities = [Entity(offset=offset, length=length, text=text, entity_id=entity_id) for _, _, entity_id, _, offset, length in sample[\"gt_entities\"]]\n",
    "predicted_entities = [Entity(offset=offset, length=length, text=text, entity_id=entity_id, md_score=md_score, el_score=el_score) for offset, length, entity_id, md_score, el_score in zip(prediction[\"offsets\"], prediction[\"lengths\"], prediction[\"entities\"], prediction[\"md_scores\"], prediction[\"el_scores\"])]\n",
    "print_sample(text, ground_truth_entities, predicted_entities, max_display_length=100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cca8e49",
   "metadata": {},
   "source": [
    "# Debug mention detection bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef3af39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 15\n",
      "74 23\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth_entities[0].offset, ground_truth_entities[0].length)\n",
    "print(predicted_entities[0].offset, predicted_entities[0].length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6b2f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text[:max_display_length]='Taylor Swift is a singer.'\n",
      "***************** Ground truth entities *****************\n",
      "len(ground_truth_entities)=0\n",
      "***************** Predicted entities *****************\n",
      "len(predicted_entities)=1\n",
      "mention=\"Taylor Swift\" -> entity_id=Q26876 (md_score=0.15, el_score=0.02)\n"
     ]
    }
   ],
   "source": [
    "# Set low thresholds\n",
    "model_eval.task.md_threshold = 0.1\n",
    "model_eval.task.el_threshold = 0.1\n",
    "text = \"Taylor Swift is a singer.\"\n",
    "prediction = model_eval.process_batch([text])[0]\n",
    "predicted_entities = [PredictedEntity(offset, length, text, entity_id, md_score, el_score) for offset, length, entity_id, md_score, el_score in zip(prediction[\"offsets\"], prediction[\"lengths\"], prediction[\"entities\"], prediction[\"md_scores\"], prediction[\"el_scores\"])]\n",
    "print_sample(text, [], predicted_entities)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd802abc",
   "metadata": {},
   "source": [
    "## SPM Encode and Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59b7563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4081, 106383, 4, 1839]\n",
      ". Her\n"
     ]
    }
   ],
   "source": [
    "text = \"400 metres.  Her\"\n",
    "print(model_eval.transform.processor.encode(text))\n",
    "print(model_eval.transform.processor.decode([4, 1839]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b2f8015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['track', 'and', 'field']\n",
      "Martina Steuk (née Kämpfert; born 11 November 1959) is a German former\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 15)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sp_offset = 19\n",
    "sp_length = 4\n",
    "#text = \"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany. She competed in the 800 metres and occasionally the 400 metres.  Her first success came at the 1977 European Athletics Junior Championships, where she won the 800 m title. At twenty years old, reached the final at the 1980 Moscow Olympics and placed fourth in a lifetime best time of 1:56.21 behind a Soviet trio of Nadiya Olizarenko, Olga Mineyeva and Tatyana Providokhina that broke the world record. A successful 1981 season followed, which included a win at the 1981 European Cup, and at the 1981 IAAF World Cup she won an 800 m silver behind Lyudmila Veselkova and a gold with the East German 4 × 400 metres relay team. She ranked second in the world that year for the 800 m behind Vesselkova with a time of 1:57.16. That success continued into 1982 with a silver medal at the 1982 European Athletics Indoor Championships, finishing second only to Romania's Doina Melinte.\"\n",
    "#token_ids = model_eval.transform.processor.encode(text)\n",
    "#mention_token_ids = token_ids[sp_offset:sp_offset+sp_length]\n",
    "#[model_eval.transform.processor.decode([token_id]) for token_id in mention_token_ids]\n",
    "convert_sp_to_char_offsets(text, sp_offset, sp_length, model_eval.transform.processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convert_sp_to_char_offsets(spm_processor):\n",
    "    text = \"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany.   \"\n",
    "    sp_offset = 19\n",
    "    sp_length = 4\n",
    "    sp_offset -= 1  # sp_offsets include cls_token, while boundaries doesn't\n",
    "    sp_length -= 1  # TODO: it is not clear why we need to subtract 1\n",
    "    char_offset, char_length = convert_sp_to_char_offsets(text, sp_offset, sp_length, spm_processor)\n",
    "    assert text[char_offset: char_offset + char_length] == \"track and field\", f\"Expected 'track and field', got '{text[char_offset: char_offset + char_length]}'\"\n",
    "\n",
    "\n",
    "spm_processor = model_eval.transform.processor\n",
    "spm_processor.EncodeAsPieces(text)\n",
    "test_sentencepiece_to_char_conversion(spm_processor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2930a292",
   "metadata": {},
   "source": [
    "# Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4388e8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12679it [00:00, 70671.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 12679 texts, batch_size=1024, model_eval.transform.max_seq_len=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [04:00, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 50s, sys: 35.3 s, total: 12min 25s\n",
      "Wall time: 4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def batch_samples(samples, batch_size):\n",
    "    # Yield batches of samples\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        yield samples[i : i + batch_size]\n",
    "\n",
    "\n",
    "texts = [sample[\"original_text\"] for sample in load_file(\"/fsx/movb/data/matcha/mewsli-9/en.jsonl\")]\n",
    "batch_size = 1024\n",
    "print(f\"Processing {len(texts)} texts, {batch_size=}, {model_eval.transform.max_seq_len=}\")\n",
    "%time _ = [model_eval.process_batch(batch_texts) for batch_texts in tqdm(batch_samples(texts, batch_size), desc=\"Inference\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e9e7307",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sample:\n",
    "    text: str\n",
    "    ground_truth_entities: List[Entity]\n",
    "    predicted_entities: List[Entity]\n",
    "\n",
    "    def __init__(self, text, ground_truth_entities, predicted_entities):\n",
    "        self.text = text\n",
    "        self.ground_truth_entities = ground_truth_entities\n",
    "        self.predicted_entities = predicted_entities\n",
    "        # Compute scores\n",
    "        self.true_positives = [predicted_entity for predicted_entity in self.predicted_entities if predicted_entity in self.ground_truth_entities]\n",
    "        self.false_positives = [predicted_entity for predicted_entity in self.predicted_entities if predicted_entity not in self.ground_truth_entities]\n",
    "        self.false_negatives = [ground_truth_entity for ground_truth_entity in self.ground_truth_entities if ground_truth_entity not in self.predicted_entities]\n",
    "        # Bag of entities\n",
    "        gold_entity_ids = set([ground_truth_entity.entity_id for ground_truth_entity in self.ground_truth_entities])\n",
    "        predicted_entity_ids = set([predicted_entity.entity_id for predicted_entity in self.predicted_entities])\n",
    "        self.true_positives_boe = [predicted_entity_id for predicted_entity_id in predicted_entity_ids if predicted_entity_id in gold_entity_ids]\n",
    "        self.false_positives_boe = [predicted_entity_id for predicted_entity_id in predicted_entity_ids if predicted_entity_id not in gold_entity_ids]\n",
    "        self.false_negatives_boe = [ground_truth_entity_id for ground_truth_entity_id in gold_entity_ids if ground_truth_entity_id not in predicted_entity_ids]\n",
    "\n",
    "\n",
    "    def print(self, max_display_length=1000):\n",
    "        print(f\"{self.text[:max_display_length]=}\")\n",
    "        print(\"***************** Ground truth entities *****************\")\n",
    "        print(f\"{len(self.ground_truth_entities)=}\")\n",
    "        for ground_truth_entity in self.ground_truth_entities:\n",
    "            if ground_truth_entity.offset + ground_truth_entity.length > max_display_length:\n",
    "                continue\n",
    "            print(ground_truth_entity)\n",
    "        print(\"***************** Predicted entities *****************\")\n",
    "        print(f\"{len(self.predicted_entities)=}\")\n",
    "        for predicted_entity in self.predicted_entities:\n",
    "            if predicted_entity.offset + predicted_entity.length > max_display_length:\n",
    "                continue\n",
    "            print(predicted_entity)\n",
    "\n",
    "\n",
    "\n",
    "class ModelResults:\n",
    "    def __init__(self, data, predictions, md_threshold=0.2, el_threshold=0.05, verbose=False):\n",
    "        self.data = data\n",
    "        self.predictions = predictions\n",
    "        self.md_threshold = md_threshold\n",
    "        self.el_threshold = el_threshold\n",
    "        self.verbose = verbose\n",
    "        self.samples = []\n",
    "        self._compute_scores()\n",
    "\n",
    "    def _compute_scores(self):\n",
    "        self.samples = []\n",
    "        for ground_truth_sample, predicted_sample in zip(self.data, self.predictions):\n",
    "            ground_truth_entities = [\n",
    "                GroundTruthEntity(\n",
    "                    offset=offset,\n",
    "                    length=length,\n",
    "                    text=ground_truth_sample['original_text'],\n",
    "                    entity_id=ent_id,\n",
    "                )\n",
    "                for offset, length, ent_id, _, _, _ in ground_truth_sample['gt_entities']\n",
    "            ]\n",
    "            predicted_entities = [\n",
    "                PredictedEntity(\n",
    "                    offset=offset,\n",
    "                    length=length,\n",
    "                    text=ground_truth_sample['original_text'],\n",
    "                    entity_id=ent_id,\n",
    "                    md_score=md_score,\n",
    "                    el_score=el_score,\n",
    "                )\n",
    "                for offset, length, ent_id, md_score, el_score in zip(\n",
    "                    predicted_sample['offsets'],\n",
    "                    predicted_sample['lengths'],\n",
    "                    predicted_sample['entities'],\n",
    "                    predicted_sample['md_scores'],\n",
    "                    predicted_sample['el_scores'],\n",
    "                )\n",
    "                if (el_score > self.el_threshold and md_score > self.md_threshold)\n",
    "            ]\n",
    "            sample = Sample(\n",
    "                text=ground_truth_sample['original_text'],\n",
    "                ground_truth_entities=ground_truth_entities,\n",
    "                predicted_entities=predicted_entities,\n",
    "            )\n",
    "            self.samples.append(sample)\n",
    "        \n",
    "        def safe_division(numerator, denominator):\n",
    "            return numerator / denominator if denominator > 0 else 0.0\n",
    "\n",
    "        self.precision = safe_division(\n",
    "            sum([len(sample.true_positives) for sample in self.samples]),\n",
    "            sum([len(sample.predicted_entities) for sample in self.samples]),\n",
    "        )\n",
    "        self.recall = safe_division(\n",
    "            sum([len(sample.true_positives) for sample in self.samples]),\n",
    "            # TODO: Check that we can't predict the same entity twice\n",
    "            sum([len(sample.ground_truth_entities) for sample in self.samples]),\n",
    "        )\n",
    "        self.f1 = safe_division(2 * self.precision * self.recall, self.precision + self.recall)\n",
    "        self.precision_boe = safe_division(\n",
    "            sum([len(sample.true_positives_boe) for sample in self.samples]),\n",
    "            sum([len(sample.predicted_entities) for sample in self.samples]),\n",
    "        )\n",
    "        self.recall_boe = safe_division(\n",
    "            sum([len(sample.true_positives_boe) for sample in self.samples]),\n",
    "            sum([len(sample.ground_truth_entities) for sample in self.samples]),\n",
    "        )\n",
    "        self.f1_boe = safe_division(2 * self.precision_boe * self.recall_boe, self.precision_boe + self.recall_boe)\n",
    "        #return (f1, precision, recall), (f1_boe, precision_boe, recall_boe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "235bcda9aabf5f8363267684c8e0d7a57e9fb12569fe58ae215aef35e2f0a58c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
