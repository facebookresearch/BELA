{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff95f192-5b1e-4caf-a5cc-3290b0aebf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a100-st-p4d24xlarge-18\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yaml\n",
    "from hydra.experimental import compose, initialize_config_module\n",
    "import hydra\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import faiss\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "\n",
    "from bela.transforms.spm_transform import SPMTransform\n",
    "from bela.evaluation.model_eval import ModelEval, load_file\n",
    "from bela.utils.prediction_utils import get_predictions_using_windows\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "!cat /etc/hostname  # Double check that we are on a gpu node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2db8ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GroundTruthEntity:\n",
    "    offset: int\n",
    "    length: int\n",
    "    text: str\n",
    "    entity_id: str\n",
    "\n",
    "    @property\n",
    "    def mention(self):\n",
    "        return self.text[self.offset : self.offset + self.length]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"mention=\\\"{self.mention}\\\" -> entity_id={self.entity_id}\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PredictedEntity:\n",
    "    offset: int\n",
    "    length: int\n",
    "    text: str\n",
    "    entity_id: str\n",
    "    md_score: float\n",
    "    el_score: float\n",
    "\n",
    "    @property\n",
    "    def mention(self):\n",
    "        return self.text[self.offset : self.offset + self.length]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"mention=\\\"{self.mention}\\\" -> entity_id={self.entity_id} (md_score={self.md_score:.2f}, el_score={self.el_score:.2f})\"\n",
    "\n",
    "\n",
    "def print_sample(text: str, ground_truth_entities: List[GroundTruthEntity], predicted_entities: List[PredictedEntity], max_display_length=1000):\n",
    "    print(f\"{text[:max_display_length]=}\")\n",
    "    print(\"***************** Ground truth entities *****************\")\n",
    "    print(f\"{len(ground_truth_entities)=}\")\n",
    "    for ground_truth_entity in ground_truth_entities:\n",
    "        if ground_truth_entity.offset + ground_truth_entity.length > max_display_length:\n",
    "            continue\n",
    "        print(ground_truth_entity)\n",
    "    print(\"***************** Predicted entities *****************\")\n",
    "    print(f\"{len(predicted_entities)=}\")\n",
    "    for predicted_entity in predicted_entities:\n",
    "        if predicted_entity.offset + predicted_entity.length > max_display_length:\n",
    "            continue\n",
    "        print(predicted_entity)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f8f2dc7",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf93bf95-295e-4efd-8133-bd9aedf156d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         170161569 function calls (170084442 primitive calls) in 110.106 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 6805 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      " 44771119   22.447    0.000   22.447    0.000 {method 'readline' of 'mmap.mmap' objects}\n",
      "        3   22.347    7.449   50.189   16.730 joint_el_datamodule.py:47(__init__)\n",
      "       67   12.799    0.191   12.802    0.191 serialization.py:994(load_tensor)\n",
      "        1   12.300   12.300   12.300   12.300 {built-in method faiss._swigfaiss.GpuIndexFlat_add}\n",
      "        1    9.243    9.243   10.246   10.246 joint_el_datamodule.py:21(__init__)\n",
      "        1    4.084    4.084    4.084    4.084 {built-in method faiss._swigfaiss.new_GpuIndexFlatIP}\n",
      "        1    3.742    3.742  110.110  110.110 <string>:2(<module>)\n",
      " 61313958    3.383    0.000    3.383    0.000 {method 'append' of 'list' objects}\n",
      " 44771116    2.724    0.000    2.724    0.000 {method 'tell' of 'mmap.mmap' objects}\n",
      "        1    2.189    2.189  106.367  106.367 model_eval.py:60(__init__)"
     ]
    }
   ],
   "source": [
    "%%prun -s tottime -l 10\n",
    "\n",
    "# e2e model with isotropic embeddings\n",
    "checkpoint_path = '/checkpoints/movb/bela/2023-01-13-023711/0/lightning_logs/version_4144/checkpoints/last.ckpt'  # Not working: Unexpected key(s) in state_dict: \"saliency_encoder.mlp.0.weight\", \"saliency_encoder.mlp.0.bias\", \"saliency_encoder.mlp.3.weight\", \"saliency_encoder.mlp.3.bias\", \"saliency_encoder.mlp.6.weight\", \"saliency_encoder.mlp.6.bias\". \n",
    "checkpoint_path = '/checkpoints/movb/bela/2022-11-27-225013/0/lightning_logs/version_286287/checkpoints/last_15000.ckpt'  # Works but 0 F1\n",
    "\n",
    "# E2E checkpoint with new embeddings\n",
    "# https://fb.quip.com/QVUxA4UcAZ7k#temp:C:OcG977f71fab43d42379521a0dff\n",
    "# Works but give 0 F1 on tackbp (mention detection is okish, but entity disambiguation is random)\n",
    "checkpoint_path = '/checkpoints/movb/bela/2023-01-18-220105/0/lightning_logs/version_4820/checkpoints/last.ckpt'  \n",
    "#model_eval = ModelEval(checkpoint_path, config_name=\"joint_el_mel_new\")\n",
    "model_eval = ModelEval(checkpoint_path, config_name=\"joint_el_mel_new_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0516d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set low thresholds\n",
    "model_eval.task.md_threshold = 0.01\n",
    "model_eval.task.el_threshold = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9df37725",
   "metadata": {},
   "source": [
    "# End-to-end Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "000fd83c-fd03-4e8a-a3da-d8df70477d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_eval.checkpoint_path='/checkpoints/movb/bela/2023-01-18-220105/0/lightning_logs/version_4820/checkpoints/last.ckpt'\n",
      "model_eval.task.md_threshold=0.01\n",
      "model_eval.task.el_threshold=0.01\n",
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "269it [00:00, 9825.29it/s]\n",
      " 50%|████████████████████████████████                                | 2/4 [01:01<01:01, 30.51s/it]"
     ]
    }
   ],
   "source": [
    "print(f\"{model_eval.checkpoint_path=}\")\n",
    "print(f\"{model_eval.task.md_threshold=}\")\n",
    "print(f\"{model_eval.task.el_threshold=}\")\n",
    "datasets = [\n",
    "    \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format.jsonl\",\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ta.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ar.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/en.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/fa.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/sr.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/tr.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/de.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/es.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ja.jsonl',\n",
    "]\n",
    "for test_data_path in datasets:\n",
    "    print(f\"Processing {test_data_path}\")\n",
    "    test_data = load_file(test_data_path)\n",
    "    #test_data = test_data[:1000]\n",
    "    \n",
    "    predictions = get_predictions_using_windows(model_eval, test_data)\n",
    "    (f1, precision, recall), (f1_boe, precision_boe, recall_boe) = ModelEval.compute_scores(test_data, predictions)\n",
    "    \n",
    "    print(f\"F1 = {f1:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\")\n",
    "    print(f\"F1 boe = {f1_boe:.4f}, precision = {precision_boe:.4f}, recall = {recall_boe:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da72624",
   "metadata": {},
   "source": [
    "# Disambiguation Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shift_shift(text):\n",
    "    for idx,ch in enumerate(text):\n",
    "        if not ch.isalpha():\n",
    "            return idx\n",
    "\n",
    "def convert_data_for_disambiguation(data, lang):\n",
    "    # convert examples to 1 entity per example and shift if needed\n",
    "    if lang=='ar':\n",
    "        MAX_LENGTH = 600\n",
    "        MAX_OFFSET = 400\n",
    "    elif lang == 'ja':\n",
    "        MAX_LENGTH = 350\n",
    "        MAX_OFFSET = 250\n",
    "    else:\n",
    "        MAX_LENGTH = 800\n",
    "        MAX_OFFSET = 600\n",
    "    new_examples = []\n",
    "    for example in tqdm(data):\n",
    "        original_text = example['original_text']\n",
    "        for _, _, ent, _, offset, length in example['gt_entities']:\n",
    "            shift = 0\n",
    "            if len(original_text) > MAX_LENGTH and offset > MAX_OFFSET:\n",
    "                shift = (offset - MAX_OFFSET)\n",
    "                shift += shift_shift(original_text[shift:])\n",
    "            new_example = {\n",
    "                'original_text': original_text[shift:],\n",
    "                'gt_entities': [[0,0,ent,_,offset-shift,length]],\n",
    "            }\n",
    "            new_examples.append(new_example)\n",
    "    return new_examples\n",
    "\n",
    "\n",
    "def metrics_disambiguation(test_data, predictions):\n",
    "    support = 0\n",
    "    support_only_predicted = 0\n",
    "    correct = 0\n",
    "    incorrect_pos = 0\n",
    "\n",
    "    for example_idx, (example, prediction) in tqdm(enumerate(zip(test_data, predictions))):\n",
    "#         targets = {\n",
    "#             (offset,length):ent_id\n",
    "#             for _,_,ent_id,_,offset,length in example['gt_entities']\n",
    "#         }\n",
    "#         prediction = {\n",
    "#             (offset,length):ent_id\n",
    "#             for offset,length,ent_id in zip(prediction['offsets'], prediction['lengths'], prediction['entities'])\n",
    "#         }\n",
    "\n",
    "#         support += len(targets)\n",
    "#         support_only_predicted += len(prediction)\n",
    "        \n",
    "#         correct += sum(1 for pos,ent_id in prediction.items() if (pos in targets and targets[pos] == ent_id))\n",
    "#         incorrect_pos += sum(1 for pos,_ in prediction.items() if pos not in targets)\n",
    "        if len(prediction['entities']) == 0:\n",
    "            continue\n",
    "        target = example['gt_entities'][0][2]\n",
    "        prediction = prediction['entities'][0]\n",
    "        correct += (target == prediction)\n",
    "        support += 1\n",
    "\n",
    "    accuracy = correct/support\n",
    "    # accuracy_only_predicted = correct/support_only_predicted\n",
    "\n",
    "    return accuracy, support #, accuracy_only_predicted, support_only_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ta.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ar.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/en.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/fa.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/sr.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/tr.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/de.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/es.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ja.jsonl',\n",
    "]\n",
    "for test_data_path in datasets:\n",
    "    print(f\"Processing {test_data_path}\")\n",
    "    lang = test_data_path[-8:-6]\n",
    "    test_data = load_file(test_data_path)\n",
    "    test_data = convert_data_for_disambiguation(test_data[:10000], lang)\n",
    "    predictions = model_eval.get_disambiguation_predictions(test_data)\n",
    "    accuracy, support = metrics_disambiguation(test_data, predictions)\n",
    "    print(f\"Accuracty {accuracy}, support {support}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2930a292",
   "metadata": {},
   "source": [
    "# Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4388e8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12679it [00:00, 70671.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 12679 texts, batch_size=1024, model_eval.transform.max_seq_len=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [04:00, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 50s, sys: 35.3 s, total: 12min 25s\n",
      "Wall time: 4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def batch_samples(samples, batch_size):\n",
    "    # Yield batches of samples\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        yield samples[i : i + batch_size]\n",
    "\n",
    "\n",
    "texts = [sample[\"original_text\"] for sample in load_file(\"/fsx/movb/data/matcha/mewsli-9/en.jsonl\")]\n",
    "batch_size = 1024\n",
    "print(f\"Processing {len(texts)} texts, {batch_size=}, {model_eval.transform.max_seq_len=}\")\n",
    "%time _ = [model_eval.process_batch(batch_texts) for batch_texts in tqdm(batch_samples(texts, batch_size), desc=\"Inference\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eff17084",
   "metadata": {},
   "source": [
    "## Eyeball Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced14ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text[:max_display_length]='Taylor Swift lives in New York City. New York City is a city in the United States.'\n",
      "***************** Ground truth entities *****************\n",
      "len(ground_truth_entities)=0\n",
      "***************** Predicted entities *****************\n",
      "len(predicted_entities)=19\n",
      "mention=\"Taylor\" -> entity_id=Q26876 (md_score=0.01, el_score=0.03)\n",
      "mention=\"Taylor Swift lives\" -> entity_id=Q26876 (md_score=0.58, el_score=0.78)\n",
      "mention=\"Taylor Swift lives in New York City. New\" -> entity_id=Q26876 (md_score=0.04, el_score=0.53)\n",
      "mention=\"Swift lives\" -> entity_id=Q26876 (md_score=0.02, el_score=0.06)\n",
      "mention=\"lives\" -> entity_id=Q26876 (md_score=0.03, el_score=0.01)\n",
      "mention=\"New York City. New\" -> entity_id=Q60 (md_score=0.13, el_score=0.19)\n",
      "mention=\"York City\" -> entity_id=Q60 (md_score=0.01, el_score=0.01)\n",
      "mention=\"York City.\" -> entity_id=Q60 (md_score=0.04, el_score=0.03)\n",
      "mention=\"York City. New\" -> entity_id=Q60 (md_score=0.41, el_score=0.45)\n",
      "mention=\"York City. New York City is\" -> entity_id=Q60 (md_score=0.03, el_score=0.02)\n",
      "mention=\"City. New\" -> entity_id=Q60 (md_score=0.04, el_score=0.03)\n",
      "mention=\". New\" -> entity_id=Q60 (md_score=0.01, el_score=0.01)\n",
      "mention=\"New\" -> entity_id=Q60 (md_score=0.12, el_score=0.07)\n",
      "mention=\"York\" -> entity_id=Q60 (md_score=0.02, el_score=0.01)\n",
      "mention=\"York City is\" -> entity_id=Q60 (md_score=0.06, el_score=0.12)\n",
      "mention=\"city in\" -> entity_id=Q515 (md_score=0.01, el_score=0.01)\n",
      "mention=\"United\" -> entity_id=Q30 (md_score=0.02, el_score=0.00)\n",
      "mention=\"United States\" -> entity_id=Q30 (md_score=0.02, el_score=0.01)\n",
      "mention=\"United States.\" -> entity_id=Q30 (md_score=0.05, el_score=0.05)\n"
     ]
    }
   ],
   "source": [
    "text = \"Taylor Swift lives in New York City. New York City is a city in the United States.\"\n",
    "prediction = model_eval.process_batch([text])[0]\n",
    "predicted_entities = [PredictedEntity(offset, length, text, entity_id, md_score, el_score) for offset, length, entity_id, md_score, el_score in zip(prediction[\"offsets\"], prediction[\"lengths\"], prediction[\"entities\"], prediction[\"md_scores\"], prediction[\"el_scores\"])]\n",
    "print_sample(text, [], predicted_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77ac96a-b29e-45c3-9ab1-43ddcd387572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "269it [00:00, 8626.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text[:max_display_length]='<DOC id=\"ENG_NW_001048_20150228_F0000001S\"> <SOURCE>http://www.telegraph.co.uk/news/worldnews/europe/russia/11441729/David-Cameron-says-callous-murder-of-Boris-Nemtsov-must-be-rapidly-investigated.html</SOURCE> <DATE_TIME>2015-02-28T00:00:00</DATE_TIME> <HEADLINE> David Cameron says \\'callous murder\\' of Boris Nemtsov must be rapidly investigated </HEADLINE> <TEXT> <P> Prime Minister says \"callous murder\" of Russian opposition politician \"must be fully, rapidly and transparently investigated, and those responsible brought to justice\" </P> <P> David Cameron has said he is \"shocked and sickened\" by the murder of Boris Nemtsov. </P> <P> The Prime Minister said the \"callous\" killing of the Russian opposition politician \"must be fully, rapidly and transparently investigated, and those responsible brought to justice\". </P> <P> Mr Nemtsov, a leading critic of president Vladimir Putin and of the war in Ukraine, was gunned down near the Kremlin on the eve of a major rally in Moscow. </P> <P> “I a'\n",
      "***************** Ground truth entities *****************\n",
      "len(ground_truth_entities)=33\n",
      "mention=\"Vladimir Putin\" -> entity_id=Q7747\n",
      "mention=\"Ukraine\" -> entity_id=Q212\n",
      "mention=\"Kremlin\" -> entity_id=Q133274\n",
      "mention=\"Moscow\" -> entity_id=Q649\n",
      "mention=\"Russian\" -> entity_id=Q159\n",
      "mention=\"Russian\" -> entity_id=Q159\n",
      "mention=\"David Cameron\" -> entity_id=Q192\n",
      "mention=\"David-Cameron\" -> entity_id=Q192\n",
      "mention=\"David Cameron\" -> entity_id=Q192\n",
      "mention=\"Prime Minister\" -> entity_id=Q192\n",
      "mention=\"Prime Minister\" -> entity_id=Q192\n",
      "mention=\"politician\" -> entity_id=Q363846\n",
      "mention=\"Boris Nemtsov\" -> entity_id=Q363846\n",
      "mention=\"politician\" -> entity_id=Q363846\n",
      "mention=\"Nemtsov\" -> entity_id=Q363846\n",
      "mention=\"Boris-Nemtsov\" -> entity_id=Q363846\n",
      "mention=\"Boris Nemtsov\" -> entity_id=Q363846\n",
      "***************** Predicted entities *****************\n",
      "len(predicted_entities)=51\n",
      "mention=\"telegraph.co.uk/news/worldnews/europe/russia/11441729/David\" -> entity_id=Q192621 (md_score=0.02, el_score=0.01)\n",
      "mention=\"\" -> entity_id=Q159 (md_score=0.01, el_score=0.00)\n",
      "mention=\"David Cameron says\" -> entity_id=Q192 (md_score=0.03, el_score=0.19)\n",
      "mention=\"Boris Nemtsov must\" -> entity_id=Q363846 (md_score=0.10, el_score=0.24)\n",
      "mention=\"Prime Minister says\" -> entity_id=Q192 (md_score=0.02, el_score=0.06)\n",
      "mention=\"Russian opposition politician\" -> entity_id=Q3023172 (md_score=0.04, el_score=0.01)\n",
      "mention=\"David Cameron has\" -> entity_id=Q192 (md_score=0.52, el_score=0.61)\n",
      "mention=\"Boris Nemtsov.\" -> entity_id=Q363846 (md_score=0.12, el_score=0.19)\n",
      "mention=\"Prime Minister said\" -> entity_id=Q14211 (md_score=0.04, el_score=0.05)\n",
      "mention=\"Russian opposition politician\" -> entity_id=Q3023172 (md_score=0.04, el_score=0.01)\n",
      "mention=\"Vladimir Putin and\" -> entity_id=Q7747 (md_score=0.66, el_score=0.75)\n",
      "mention=\"Ukraine, was\" -> entity_id=Q212 (md_score=0.09, el_score=0.12)\n",
      "mention=\"Kremlin on\" -> entity_id=Q133274 (md_score=0.35, el_score=0.50)\n",
      "mention=\"rally in\" -> entity_id=Q111296507 (md_score=0.03, el_score=0.03)\n",
      "mention=\"Moscow.\" -> entity_id=Q649 (md_score=0.10, el_score=0.28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_path = \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format.jsonl\"\n",
    "print(f\"Processing {test_data_path}\")\n",
    "test_data = load_file(test_data_path)\n",
    "sample = test_data[200]\n",
    "prediction = get_predictions_using_windows(model_eval, [sample])[0]\n",
    "text = sample[\"original_text\"]\n",
    "max_length = 1024\n",
    "\n",
    "ground_truth_entities = [GroundTruthEntity(offset, length, text, entity_id) for _, _, entity_id, _, offset, length in sample[\"gt_entities\"]]\n",
    "predicted_entities = [PredictedEntity(offset, length, text, entity_id, md_score, el_score) for offset, length, entity_id, md_score, el_score in zip(prediction[\"offsets\"], prediction[\"lengths\"], prediction[\"entities\"], prediction[\"md_scores\"], prediction[\"el_scores\"])]\n",
    "print_sample(text, ground_truth_entities, predicted_entities, max_display_length=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e9e7307",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "235bcda9aabf5f8363267684c8e0d7a57e9fb12569fe58ae215aef35e2f0a58c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
