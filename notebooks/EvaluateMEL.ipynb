{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff95f192-5b1e-4caf-a5cc-3290b0aebf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a100-st-p4d24xlarge-48\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yaml\n",
    "from hydra.experimental import compose, initialize_config_module\n",
    "import hydra\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import faiss\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "\n",
    "from bela.transforms.spm_transform import SPMTransform\n",
    "from bela.evaluation.model_eval import ModelEval, load_file, Entity\n",
    "from bela.utils.prediction_utils import get_predictions_using_windows\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "!cat /etc/hostname  # Double check that we are on a gpu node"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f8f2dc7",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf93bf95-295e-4efd-8133-bd9aedf156d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path='bela.transforms.joint_el_transform.JointELXlmrRawTextTransform', mod='bela.transforms.joint_el_transform'\n",
      "path='bela.datamodule.joint_el_datamodule.JointELDataModule', mod='bela.datamodule'\n",
      "path='bela.datamodule.joint_el_datamodule.JointELDataModule', mod='bela.datamodule.joint_el_datamodule'\n",
      "path='bela.task.joint_el_task.JointELTask', mod='bela.task'\n",
      "path='bela.task.joint_el_task.JointELTask', mod='bela.task.joint_el_task'\n",
      "path='bela.models.hf_encoder.HFEncoder', mod='bela.models'\n",
      "path='bela.models.hf_encoder.HFEncoder', mod='bela.models.hf_encoder'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         170162428 function calls (170085301 primitive calls) in 165.376 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "   List reduced from 6806 to 10 due to restriction <10>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      " 44771119   59.508    0.000   59.508    0.000 {method 'readline' of 'mmap.mmap' objects}\n",
      "        3   29.145    9.715   95.733   31.911 joint_el_datamodule.py:47(__init__)\n",
      "        1   14.731   14.731   14.731   14.731 {built-in method faiss._swigfaiss.GpuIndexFlat_add}\n",
      "        5   13.854    2.771   13.855    2.771 serialization.py:994(load_tensor)\n",
      "        1   10.297   10.297   11.449   11.449 joint_el_datamodule.py:21(__init__)\n",
      " 61313960    4.177    0.000    4.177    0.000 {method 'append' of 'list' objects}\n",
      "        1    3.759    3.759    3.759    3.759 {built-in method faiss._swigfaiss.new_GpuIndexFlatIP}\n",
      " 44771116    3.713    0.000    3.713    0.000 {method 'tell' of 'mmap.mmap' objects}\n",
      "        1    3.358    3.358  162.675  162.675 model_eval.py:102(__init__)\n",
      "        1    2.705    2.705  165.379  165.379 <string>:2(<module>)"
     ]
    }
   ],
   "source": [
    "%%prun -s tottime -l 10\n",
    "\n",
    "# e2e model with isotropic embeddings\n",
    "checkpoint_path = '/checkpoints/movb/bela/2023-01-13-023711/0/lightning_logs/version_4144/checkpoints/last.ckpt'  # Not working: Unexpected key(s) in state_dict: \"saliency_encoder.mlp.0.weight\", \"saliency_encoder.mlp.0.bias\", \"saliency_encoder.mlp.3.weight\", \"saliency_encoder.mlp.3.bias\", \"saliency_encoder.mlp.6.weight\", \"saliency_encoder.mlp.6.bias\". \n",
    "checkpoint_path = '/checkpoints/movb/bela/2022-11-27-225013/0/lightning_logs/version_286287/checkpoints/last_15000.ckpt'  # Works but 0 F1\n",
    "\n",
    "# E2E checkpoint with new embeddings\n",
    "# https://fb.quip.com/QVUxA4UcAZ7k#temp:C:OcG977f71fab43d42379521a0dff\n",
    "# Works but give 0 F1 on tackbp (mention detection is okish, but entity disambiguation is random)\n",
    "checkpoint_path = '/checkpoints/movb/bela/2023-01-18-220105/0/lightning_logs/version_4820/checkpoints/last.ckpt'  \n",
    "# Overfit on one sample from /fsx/louismartin/bela/data/debug_mention_detection/mel/train.1st.1_sample.txt\n",
    "checkpoint_path = '/data/home/louismartin/dev/BELA/multirun/2023-02-14/08-45-13/0/lightning_logs/version_0/checkpoints/checkpoint_best.ckpt'\n",
    "checkpoint_path = \"/data/home/louismartin/dev/BELA/multirun/2023-02-15/15-59-33/0/lightning_logs/version_0/checkpoints/checkpoint_best.ckpt\"\n",
    "checkpoint_path = \"/data/home/louismartin/dev/BELA/multirun/2023-02-15/16-16-51/0/lightning_logs/version_0/checkpoints/checkpoint_best-v1.ckpt\"\n",
    "model_eval = ModelEval(checkpoint_path, config_name=\"joint_el_mel_new_index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9df37725",
   "metadata": {},
   "source": [
    "# End-to-end Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000fd83c-fd03-4e8a-a3da-d8df70477d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_eval.checkpoint_path='/data/home/louismartin/dev/BELA/multirun/2023-02-15/15-59-33/0/lightning_logs/version_0/checkpoints/checkpoint_best.ckpt'\n",
      "model_eval.task.md_threshold=0.2\n",
      "model_eval.task.el_threshold=0.4\n",
      "Processing /fsx/louismartin/bela/data/debug_mention_detection/mel/eval.1st.1_sample.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:00, 33019.35it/s]\n",
      "100%|███████████████████████████| 1/1 [00:00<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.4500, precision = 0.5625, recall = 0.3750\n",
      "F1 boe = 0.8205, precision = 1.0000, recall = 0.6957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_eval.task.md_threshold = 0.2\n",
    "model_eval.task.el_threshold = 0.4\n",
    "print(f\"{model_eval.checkpoint_path=}\")\n",
    "print(f\"{model_eval.task.md_threshold=}\")\n",
    "print(f\"{model_eval.task.el_threshold=}\")\n",
    "datasets = [\n",
    "    #\"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format.jsonl\",\n",
    "    \"/fsx/louismartin/bela/data/debug_mention_detection/mel/eval.1st.1_sample.txt\",  # Overfit on one sample\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ta.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ar.jsonl',\n",
    "    ##'/fsx/movb/data/matcha/mewsli-9/en.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/fa.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/sr.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/tr.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/de.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/es.jsonl',\n",
    "    #'/fsx/movb/data/matcha/mewsli-9/ja.jsonl',\n",
    "]\n",
    "for test_data_path in datasets:\n",
    "    print(f\"Processing {test_data_path}\")\n",
    "    test_data = load_file(test_data_path)\n",
    "    test_data = test_data[:1]\n",
    "    \n",
    "    predictions = get_predictions_using_windows(model_eval, test_data, window_length=1024)\n",
    "    (f1, precision, recall), (f1_boe, precision_boe, recall_boe) = ModelEval.compute_scores(test_data, predictions)\n",
    "    #model_results = ModelResults(test_data, predictions)\n",
    "    #(f1, precision, recall), (f1_boe, precision_boe, recall_boe) = model_results.compute_scores()\n",
    "    \n",
    "    print(f\"F1 = {f1:.4f}, precision = {precision:.4f}, recall = {recall:.4f}\")\n",
    "    print(f\"F1 boe = {f1_boe:.4f}, precision = {precision_boe:.4f}, recall = {recall_boe:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc73eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "test_data = load_file(test_data_path)\n",
    "samples = model_eval.convert_data_and_predictions_to_samples(test_data, predictions, md_threshold=model_eval.task.md_threshold, el_threshold=model_eval.task.el_threshold)\n",
    "print(\"***************** Ground Truth Entities *****************\")\n",
    "pprint(samples[0].ground_truth_entities)\n",
    "print(\"***************** False Positives *****************\")\n",
    "pprint(samples[0].false_positives)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6da72624",
   "metadata": {},
   "source": [
    "# Disambiguation Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shift_shift(text):\n",
    "    for idx,ch in enumerate(text):\n",
    "        if not ch.isalpha():\n",
    "            return idx\n",
    "\n",
    "def convert_data_for_disambiguation(data, lang):\n",
    "    # convert examples to 1 entity per example and shift if needed\n",
    "    if lang=='ar':\n",
    "        MAX_LENGTH = 600\n",
    "        MAX_OFFSET = 400\n",
    "    elif lang == 'ja':\n",
    "        MAX_LENGTH = 350\n",
    "        MAX_OFFSET = 250\n",
    "    else:\n",
    "        MAX_LENGTH = 800\n",
    "        MAX_OFFSET = 600\n",
    "    new_examples = []\n",
    "    for example in tqdm(data):\n",
    "        original_text = example['original_text']\n",
    "        for _, _, ent, _, offset, length in example['gt_entities']:\n",
    "            shift = 0\n",
    "            if len(original_text) > MAX_LENGTH and offset > MAX_OFFSET:\n",
    "                shift = (offset - MAX_OFFSET)\n",
    "                shift += shift_shift(original_text[shift:])\n",
    "            new_example = {\n",
    "                'original_text': original_text[shift:],\n",
    "                'gt_entities': [[0,0,ent,_,offset-shift,length]],\n",
    "            }\n",
    "            new_examples.append(new_example)\n",
    "    return new_examples\n",
    "\n",
    "\n",
    "def metrics_disambiguation(test_data, predictions):\n",
    "    support = 0\n",
    "    support_only_predicted = 0\n",
    "    correct = 0\n",
    "    incorrect_pos = 0\n",
    "\n",
    "    for example_idx, (example, prediction) in tqdm(enumerate(zip(test_data, predictions))):\n",
    "#         targets = {\n",
    "#             (offset,length):ent_id\n",
    "#             for _,_,ent_id,_,offset,length in example['gt_entities']\n",
    "#         }\n",
    "#         prediction = {\n",
    "#             (offset,length):ent_id\n",
    "#             for offset,length,ent_id in zip(prediction['offsets'], prediction['lengths'], prediction['entities'])\n",
    "#         }\n",
    "\n",
    "#         support += len(targets)\n",
    "#         support_only_predicted += len(prediction)\n",
    "        \n",
    "#         correct += sum(1 for pos,ent_id in prediction.items() if (pos in targets and targets[pos] == ent_id))\n",
    "#         incorrect_pos += sum(1 for pos,_ in prediction.items() if pos not in targets)\n",
    "        if len(prediction['entities']) == 0:\n",
    "            continue\n",
    "        target = example['gt_entities'][0][2]\n",
    "        prediction = prediction['entities'][0]\n",
    "        correct += (target == prediction)\n",
    "        support += 1\n",
    "\n",
    "    accuracy = correct/support\n",
    "    # accuracy_only_predicted = correct/support_only_predicted\n",
    "\n",
    "    return accuracy, support #, accuracy_only_predicted, support_only_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ta.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ar.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/en.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/fa.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/sr.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/tr.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/de.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/es.jsonl',\n",
    "    '/fsx/movb/data/matcha/mewsli-9/ja.jsonl',\n",
    "]\n",
    "for test_data_path in datasets:\n",
    "    print(f\"Processing {test_data_path}\")\n",
    "    lang = test_data_path[-8:-6]\n",
    "    test_data = load_file(test_data_path)\n",
    "    test_data = convert_data_for_disambiguation(test_data[:10000], lang)\n",
    "    predictions = model_eval.get_disambiguation_predictions(test_data)\n",
    "    accuracy, support = metrics_disambiguation(test_data, predictions)\n",
    "    print(f\"Accuracty {accuracy}, support {support}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eff17084",
   "metadata": {},
   "source": [
    "## Eyeball Samples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "871973a2",
   "metadata": {},
   "source": [
    "With text directly as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced14ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.text[:max_display_length]=\"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany. She competed in the 800 metres and occasionally the 400 metres.  Her first success came at the 1977 European Athletics Junior Championships, where she won the 800 m title. At twenty years old, reached the final at the 1980 Moscow Olympics and placed fourth in a lifetime best time of 1:56.21 behind a Soviet trio of Nadiya Olizarenko, Olga Mineyeva and Tatyana Providokhina that broke the world record. A successful 1981 season followed, which included a win at the 1981 European Cup, and at the 1981 IAAF World Cup she won an 800 m silver behind Lyudmila Veselkova and a gold with the East German 4 × 400 metres relay team. She ranked second in the world that year for the 800 m behind Vesselkova with a time of 1:57.16. That success continued into 1982 with a silver medal at the 1982 European Athletics Indoor Championships, finishing second only to Romania's Doina Mel\"\n",
      "***************** Predicted entities *****************\n",
      "len(self.predicted_entities)=16\n",
      "Entity<mention=\" track and\", entity_id=Q3312129, md_score=0.98, el_score=1.00>\n",
      "Entity<mention=\" East\", entity_id=Q16957, md_score=0.98, el_score=1.00>\n",
      "Entity<mention=\" 800\", entity_id=Q271008, md_score=0.99, el_score=1.00>\n",
      "Entity<mention=\" 400\", entity_id=Q334734, md_score=0.99, el_score=1.00>\n",
      "Entity<mention=\" 1977 European Athletics Junior Championship\", entity_id=Q974310, md_score=0.96, el_score=1.00>\n",
      "Entity<mention=\" 1980 Moscow Olympic\", entity_id=Q8450, md_score=0.97, el_score=1.00>\n",
      "Entity<mention=\" Nadiya Olizar\", entity_id=Q231445, md_score=0.94, el_score=1.00>\n",
      "Entity<mention=\" Olga Mineyev\", entity_id=Q452613, md_score=0.95, el_score=1.00>\n",
      "Entity<mention=\" Tatyana Providok\", entity_id=Q452678, md_score=0.95, el_score=1.00>\n",
      "Entity<mention=\" 1981\", entity_id=Q4580115, md_score=0.98, el_score=1.00>\n",
      "Entity<mention=\" 1981 European\", entity_id=Q2999663, md_score=0.98, el_score=1.00>\n",
      "Entity<mention=\" 1981 IAAF World\", entity_id=Q1814515, md_score=0.97, el_score=1.00>\n",
      "Entity<mention=\" Lyudmila Vesel\", entity_id=Q6710553, md_score=0.97, el_score=1.00>\n",
      "Entity<mention=\" 4 × 400 metres rela\", entity_id=Q230057, md_score=0.97, el_score=1.00>\n",
      "Entity<mention=\" 1982 European Athletics Indoor Championship\", entity_id=Q265197, md_score=0.96, el_score=1.00>\n",
      "Entity<mention=\" Doina Mel\", entity_id=Q237005, md_score=0.97, el_score=1.00>\n"
     ]
    }
   ],
   "source": [
    "from bela.evaluation.model_eval import Sample\n",
    "text = \"Her name is Taylor Swift. New York City is a city in the United States.\"\n",
    "text = \"My dog is a Shiba Inu. Taylor Swift is a singer.\"\n",
    "text = \"Her name is Taylor Swift.\"\n",
    "text = \"He is the Dalai Lama. He is a Buddhist monk.\"\n",
    "text = \"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany. She competed in the 800 metres and occasionally the 400 metres.  Her first success came at the 1977 European Athletics Junior Championships, where she won the 800 m title. At twenty years old, reached the final at the 1980 Moscow Olympics and placed fourth in a lifetime best time of 1:56.21 behind a Soviet trio of Nadiya Olizarenko, Olga Mineyeva and Tatyana Providokhina that broke the world record. A successful 1981 season followed, which included a win at the 1981 European Cup, and at the 1981 IAAF World Cup she won an 800 m silver behind Lyudmila Veselkova and a gold with the East German 4 × 400 metres relay team. She ranked second in the world that year for the 800 m behind Vesselkova with a time of 1:57.16. That success continued into 1982 with a silver medal at the 1982 European Athletics Indoor Championships, finishing second only to Romania's Doina Melinte. She was top of the world indoor rankings that season with 1:59.24 minutes.  She was a three-time national champion, winning the 800 m at the East German Athletics Championships in 1981 before taking a national indoor and outdoor double in 1982.  She holds one of the fastest times for the 1000 metres at 2:30.85 minutes. This was the second fastest ever when it was set in 1980, behind Soviet runner Tatyana Providokhina, though it remained the fastest recorded electronically recorded time for ten years. It remains the best mark by an under-23 athlete and she also holds the under-23 best for the 600 metres event with 1:24.56 minutes.  Steuk was born in Berlin and was a member of her local club Berliner TSC. She married East German hammer thrower Roland Steuk in 1991. The two subsequently divorced. She was awarded the Patriotic Order of Merit for her athletic feats in 1982. \"\n",
    "prediction = model_eval.process_batch([text])[0]\n",
    "predicted_entities = [Entity(offset=offset, length=length, text=text, entity_id=entity_id, md_score=md_score, el_score=el_score) for offset, length, entity_id, md_score, el_score in zip(prediction[\"offsets\"], prediction[\"lengths\"], prediction[\"entities\"], prediction[\"md_scores\"], prediction[\"el_scores\"])]\n",
    "Sample(text=text, predicted_entities=predicted_entities).print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e95d1d34",
   "metadata": {},
   "source": [
    "From file with windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a77ac96a-b29e-45c3-9ab1-43ddcd387572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /fsx/louismartin/bela/data/debug_mention_detection/mel/eval.1st.1_sample.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "78it [00:00, 22171.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁track', '▁and', '▁field']\n",
      "\n",
      "['▁East', '▁Germany', '.']\n",
      "\n",
      "['▁metres']\n",
      "\n",
      "['▁metres', '.']\n",
      "\n",
      "['▁1977', '▁European', '▁Athletic', 's', '▁Junior', '▁Championship', 's', ',']\n",
      "\n",
      "['▁1980', '▁Moscow', '▁Olympic', 's']\n",
      "\n",
      "['diya', '▁O', 'lizar', 'enko', ',']\n",
      "\n",
      "['diya', '▁O', 'lizar', 'enko', ',', '▁Olga', '▁Mine', 'yev', 'a']\n",
      "\n",
      "['▁Olga', '▁Mine', 'yev', 'a']\n",
      "\n",
      "['yana', '▁Pro', 'vid', 'ok', 'hina']\n",
      "\n",
      "['▁1981', '▁season']\n",
      "\n",
      "['▁1981', '▁European', '▁Cup', ',']\n",
      "\n",
      "['▁1981', '▁I', 'A', 'AF', '▁World', '▁Cup']\n",
      "\n",
      "['ud', 'mila', '▁Vesel', 'kova']\n",
      "\n",
      "['▁400', '▁metres', '▁rela', 'y']\n",
      "\n",
      "['▁1982', '▁European', '▁Athletic', 's', '▁In', 'door', '▁Championship', 's', ',']\n",
      "\n",
      "['ina', '▁Mel', 'inte', '.']\n",
      "\n",
      "text[:max_display_length]=\"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany. She competed in the 800 metres and occasionally the 400 metres.  Her first success came at the 1977 European Athletics Junior Championships, where she won the 800 m title. At twenty years old, reached the final at the 1980 Moscow Olympics and placed fourth in a lifetime best time of 1:56.21 behind a Soviet trio of Nadiya Olizarenko, Olga Mineyeva and Tatyana Providokhina that broke the world record. A successful 1981 season followed, which included a win at the 1981 European Cup, and at the 1981 IAAF World Cup she won an 800 m silver behind Lyudmila Veselkova and a gold with the East German 4 × 400 metres relay team. She ranked second in the world that year for the 800 m behind Vesselkova with a time of 1:57.16. That success continued into 1982 with a silver medal at the 1982 European Athletics Indoor Championships, finishing second only to Romania's Doina Melinte. She was top of the world indoor rankings that season with 1:59.24 minutes.  She was a three-time national champion, winning the 800 m at the East German Athletics Championships in 1981 before taking a national indoor and outdoor double in 1982.  She holds one of the fastest times for the 1000 metres at 2:30.85 minutes. This was the second fastest ever when it was set in 1980, behind Soviet runner Tatyana Providokhina, though it remained the fastest recorded electronically recorded time for ten years. It remains the best mark by an under-23 athlete and she also holds the under-23 best for the 600 metres event with 1:24.56 minutes.  Steuk was born in Berlin and was a member of her local club Berliner TSC. She married East German hammer thrower Roland Steuk in 1991. The two subsequently divorced. She was awarded the Patriotic Order of Merit for her athletic feats in 1982. \"\n",
      "***************** Ground truth entities *****************\n",
      "len(ground_truth_entities)=24\n",
      "mention=\"track and field\" -> entity_id=Q3312129\n",
      "mention=\"East Germany\" -> entity_id=Q16957\n",
      "mention=\"800 metres\" -> entity_id=Q271008\n",
      "mention=\"400 metres\" -> entity_id=Q334734\n",
      "mention=\"1977 European Athletics Junior Championships\" -> entity_id=Q974310\n",
      "mention=\"1980 Moscow Olympics\" -> entity_id=Q8450\n",
      "mention=\"Nadiya Olizarenko\" -> entity_id=Q231445\n",
      "mention=\"Olga Mineyeva\" -> entity_id=Q452613\n",
      "mention=\"Tatyana Providokhina\" -> entity_id=Q452678\n",
      "mention=\"1981 season\" -> entity_id=Q4580115\n",
      "mention=\"1981 European Cup\" -> entity_id=Q2999663\n",
      "mention=\"1981 IAAF World Cup\" -> entity_id=Q1814515\n",
      "mention=\"Lyudmila Veselkova\" -> entity_id=Q6710553\n",
      "mention=\"4 × 400 metres relay\" -> entity_id=Q230057\n",
      "mention=\"1982 European Athletics Indoor Championships\" -> entity_id=Q265197\n",
      "mention=\"Doina Melinte\" -> entity_id=Q237005\n",
      "mention=\"East German Athletics Championships\" -> entity_id=Q55610396\n",
      "mention=\"1000 metres\" -> entity_id=Q1629556\n",
      "mention=\"Tatyana Providokhina\" -> entity_id=Q452678\n",
      "mention=\"under-23 athlete\" -> entity_id=Q14510042\n",
      "mention=\"600 metres\" -> entity_id=Q2817913\n",
      "mention=\"Berlin\" -> entity_id=Q64\n",
      "mention=\"Roland Steuk\" -> entity_id=Q319394\n",
      "mention=\"Patriotic Order of Merit\" -> entity_id=Q819570\n",
      "***************** Predicted entities *****************\n",
      "len(predicted_entities)=15\n",
      "mention=\"track and field\" -> entity_id=Q3312129 (md_score=1.00, el_score=1.00)\n",
      "mention=\"East Germany.\" -> entity_id=Q16957 (md_score=1.00, el_score=1.00)\n",
      "mention=\"metres\" -> entity_id=Q271008 (md_score=1.00, el_score=1.00)\n",
      "mention=\"metres.\" -> entity_id=Q334734 (md_score=1.00, el_score=1.00)\n",
      "mention=\" 1977 European Athletics Junior Championships\" -> entity_id=Q974310 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 1980 Moscow Olympic\" -> entity_id=Q8450 (md_score=0.99, el_score=1.00)\n",
      "mention=\"diya Olizarenko, Olga Mineyeva\" -> entity_id=Q55733 (md_score=0.58, el_score=0.00)\n",
      "mention=\"yana Providokhina\" -> entity_id=Q452613 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 1981 seaso\" -> entity_id=Q452678 (md_score=1.00, el_score=1.00)\n",
      "mention=\" 1981 European Cup\" -> entity_id=Q4580115 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 1981 IAAF World Cu\" -> entity_id=Q2999663 (md_score=0.99, el_score=1.00)\n",
      "mention=\"udmila Veselkova\" -> entity_id=Q1814515 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 400 metres rela\" -> entity_id=Q6710553 (md_score=0.99, el_score=1.00)\n",
      "mention=\" 1982 European Athletics Indoor Championships\" -> entity_id=Q230057 (md_score=0.99, el_score=1.00)\n",
      "mention=\"ina Melinte.\" -> entity_id=Q265197 (md_score=0.99, el_score=1.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data_path = \"/fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format.jsonl\"\n",
    "test_data_path = \"/fsx/louismartin/bela/data/debug_mention_detection/mel/eval.1st.1_sample.txt\"  # Overfit on one sample\n",
    "print(f\"Processing {test_data_path}\")\n",
    "test_data = load_file(test_data_path)\n",
    "#sample = test_data[200]\n",
    "sample = test_data[0]\n",
    "prediction = get_predictions_using_windows(model_eval, [sample], window_length=1024)[0]\n",
    "text = sample[\"original_text\"]\n",
    "max_length = 1024\n",
    "\n",
    "ground_truth_entities = [Entity(offset=offset, length=length, text=text, entity_id=entity_id) for _, _, entity_id, _, offset, length in sample[\"gt_entities\"]]\n",
    "predicted_entities = [Entity(offset=offset, length=length, text=text, entity_id=entity_id, md_score=md_score, el_score=el_score) for offset, length, entity_id, md_score, el_score in zip(prediction[\"offsets\"], prediction[\"lengths\"], prediction[\"entities\"], prediction[\"md_scores\"], prediction[\"el_scores\"])]\n",
    "print_sample(text, ground_truth_entities, predicted_entities, max_display_length=100000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cca8e49",
   "metadata": {},
   "source": [
    "# Debug mention detection bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef3af39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74 15\n",
      "74 23\n"
     ]
    }
   ],
   "source": [
    "print(ground_truth_entities[0].offset, ground_truth_entities[0].length)\n",
    "print(predicted_entities[0].offset, predicted_entities[0].length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6b2f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text[:max_display_length]='Taylor Swift is a singer.'\n",
      "***************** Ground truth entities *****************\n",
      "len(ground_truth_entities)=0\n",
      "***************** Predicted entities *****************\n",
      "len(predicted_entities)=1\n",
      "mention=\"Taylor Swift\" -> entity_id=Q26876 (md_score=0.15, el_score=0.02)\n"
     ]
    }
   ],
   "source": [
    "# Set low thresholds\n",
    "model_eval.task.md_threshold = 0.1\n",
    "model_eval.task.el_threshold = 0.1\n",
    "text = \"Taylor Swift is a singer.\"\n",
    "prediction = model_eval.process_batch([text])[0]\n",
    "predicted_entities = [PredictedEntity(offset, length, text, entity_id, md_score, el_score) for offset, length, entity_id, md_score, el_score in zip(prediction[\"offsets\"], prediction[\"lengths\"], prediction[\"entities\"], prediction[\"md_scores\"], prediction[\"el_scores\"])]\n",
    "print_sample(text, [], predicted_entities)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd802abc",
   "metadata": {},
   "source": [
    "## SPM Encode and Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59b7563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4081, 106383, 4, 1839]\n",
      ". Her\n"
     ]
    }
   ],
   "source": [
    "text = \"400 metres.  Her\"\n",
    "print(model_eval.transform.processor.encode(text))\n",
    "print(model_eval.transform.processor.decode([4, 1839]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b2f8015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['track', 'and', 'field']\n",
      "Martina Steuk (née Kämpfert; born 11 November 1959) is a German former\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70, 15)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sp_offset = 19\n",
    "sp_length = 4\n",
    "#text = \"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany. She competed in the 800 metres and occasionally the 400 metres.  Her first success came at the 1977 European Athletics Junior Championships, where she won the 800 m title. At twenty years old, reached the final at the 1980 Moscow Olympics and placed fourth in a lifetime best time of 1:56.21 behind a Soviet trio of Nadiya Olizarenko, Olga Mineyeva and Tatyana Providokhina that broke the world record. A successful 1981 season followed, which included a win at the 1981 European Cup, and at the 1981 IAAF World Cup she won an 800 m silver behind Lyudmila Veselkova and a gold with the East German 4 × 400 metres relay team. She ranked second in the world that year for the 800 m behind Vesselkova with a time of 1:57.16. That success continued into 1982 with a silver medal at the 1982 European Athletics Indoor Championships, finishing second only to Romania's Doina Melinte.\"\n",
    "#token_ids = model_eval.transform.processor.encode(text)\n",
    "#mention_token_ids = token_ids[sp_offset:sp_offset+sp_length]\n",
    "#[model_eval.transform.processor.decode([token_id]) for token_id in mention_token_ids]\n",
    "convert_sp_to_char_offsets(text, sp_offset, sp_length, model_eval.transform.processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b5ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_convert_sp_to_char_offsets(spm_processor):\n",
    "    text = \"   Martina Steuk (née Kämpfert; born 11 November 1959) is a German former track and field athlete who represented East Germany.   \"\n",
    "    sp_offset = 19\n",
    "    sp_length = 4\n",
    "    sp_offset -= 1  # sp_offsets include cls_token, while boundaries doesn't\n",
    "    sp_length -= 1  # TODO: it is not clear why we need to subtract 1\n",
    "    char_offset, char_length = convert_sp_to_char_offsets(text, sp_offset, sp_length, spm_processor)\n",
    "    assert text[char_offset: char_offset + char_length] == \"track and field\", f\"Expected 'track and field', got '{text[char_offset: char_offset + char_length]}'\"\n",
    "\n",
    "\n",
    "spm_processor = model_eval.transform.processor\n",
    "spm_processor.EncodeAsPieces(text)\n",
    "test_sentencepiece_to_char_conversion(spm_processor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2930a292",
   "metadata": {},
   "source": [
    "# Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4388e8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12679it [00:00, 70671.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 12679 texts, batch_size=1024, model_eval.transform.max_seq_len=256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [04:00, 18.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 50s, sys: 35.3 s, total: 12min 25s\n",
      "Wall time: 4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def batch_samples(samples, batch_size):\n",
    "    # Yield batches of samples\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        yield samples[i : i + batch_size]\n",
    "\n",
    "\n",
    "texts = [sample[\"original_text\"] for sample in load_file(\"/fsx/movb/data/matcha/mewsli-9/en.jsonl\")]\n",
    "batch_size = 1024\n",
    "print(f\"Processing {len(texts)} texts, {batch_size=}, {model_eval.transform.max_seq_len=}\")\n",
    "%time _ = [model_eval.process_batch(batch_texts) for batch_texts in tqdm(batch_samples(texts, batch_size), desc=\"Inference\")]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e9e7307",
   "metadata": {},
   "source": [
    "# Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003f214",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Sample:\n",
    "    text: str\n",
    "    ground_truth_entities: List[Entity]\n",
    "    predicted_entities: List[Entity]\n",
    "\n",
    "    def __init__(self, text, ground_truth_entities, predicted_entities):\n",
    "        self.text = text\n",
    "        self.ground_truth_entities = ground_truth_entities\n",
    "        self.predicted_entities = predicted_entities\n",
    "        # Compute scores\n",
    "        self.true_positives = [predicted_entity for predicted_entity in self.predicted_entities if predicted_entity in self.ground_truth_entities]\n",
    "        self.false_positives = [predicted_entity for predicted_entity in self.predicted_entities if predicted_entity not in self.ground_truth_entities]\n",
    "        self.false_negatives = [ground_truth_entity for ground_truth_entity in self.ground_truth_entities if ground_truth_entity not in self.predicted_entities]\n",
    "        # Bag of entities\n",
    "        gold_entity_ids = set([ground_truth_entity.entity_id for ground_truth_entity in self.ground_truth_entities])\n",
    "        predicted_entity_ids = set([predicted_entity.entity_id for predicted_entity in self.predicted_entities])\n",
    "        self.true_positives_boe = [predicted_entity_id for predicted_entity_id in predicted_entity_ids if predicted_entity_id in gold_entity_ids]\n",
    "        self.false_positives_boe = [predicted_entity_id for predicted_entity_id in predicted_entity_ids if predicted_entity_id not in gold_entity_ids]\n",
    "        self.false_negatives_boe = [ground_truth_entity_id for ground_truth_entity_id in gold_entity_ids if ground_truth_entity_id not in predicted_entity_ids]\n",
    "\n",
    "\n",
    "    def print(self, max_display_length=1000):\n",
    "        print(f\"{self.text[:max_display_length]=}\")\n",
    "        print(\"***************** Ground truth entities *****************\")\n",
    "        print(f\"{len(self.ground_truth_entities)=}\")\n",
    "        for ground_truth_entity in self.ground_truth_entities:\n",
    "            if ground_truth_entity.offset + ground_truth_entity.length > max_display_length:\n",
    "                continue\n",
    "            print(ground_truth_entity)\n",
    "        print(\"***************** Predicted entities *****************\")\n",
    "        print(f\"{len(self.predicted_entities)=}\")\n",
    "        for predicted_entity in self.predicted_entities:\n",
    "            if predicted_entity.offset + predicted_entity.length > max_display_length:\n",
    "                continue\n",
    "            print(predicted_entity)\n",
    "\n",
    "\n",
    "\n",
    "class ModelResults:\n",
    "    def __init__(self, data, predictions, md_threshold=0.2, el_threshold=0.05, verbose=False):\n",
    "        self.data = data\n",
    "        self.predictions = predictions\n",
    "        self.md_threshold = md_threshold\n",
    "        self.el_threshold = el_threshold\n",
    "        self.verbose = verbose\n",
    "        self.samples = []\n",
    "        self._compute_scores()\n",
    "\n",
    "    def _compute_scores(self):\n",
    "        self.samples = []\n",
    "        for ground_truth_sample, predicted_sample in zip(self.data, self.predictions):\n",
    "            ground_truth_entities = [\n",
    "                GroundTruthEntity(\n",
    "                    offset=offset,\n",
    "                    length=length,\n",
    "                    text=ground_truth_sample['original_text'],\n",
    "                    entity_id=ent_id,\n",
    "                )\n",
    "                for offset, length, ent_id, _, _, _ in ground_truth_sample['gt_entities']\n",
    "            ]\n",
    "            predicted_entities = [\n",
    "                PredictedEntity(\n",
    "                    offset=offset,\n",
    "                    length=length,\n",
    "                    text=ground_truth_sample['original_text'],\n",
    "                    entity_id=ent_id,\n",
    "                    md_score=md_score,\n",
    "                    el_score=el_score,\n",
    "                )\n",
    "                for offset, length, ent_id, md_score, el_score in zip(\n",
    "                    predicted_sample['offsets'],\n",
    "                    predicted_sample['lengths'],\n",
    "                    predicted_sample['entities'],\n",
    "                    predicted_sample['md_scores'],\n",
    "                    predicted_sample['el_scores'],\n",
    "                )\n",
    "                if (el_score > self.el_threshold and md_score > self.md_threshold)\n",
    "            ]\n",
    "            sample = Sample(\n",
    "                text=ground_truth_sample['original_text'],\n",
    "                ground_truth_entities=ground_truth_entities,\n",
    "                predicted_entities=predicted_entities,\n",
    "            )\n",
    "            self.samples.append(sample)\n",
    "        \n",
    "        def safe_division(numerator, denominator):\n",
    "            return numerator / denominator if denominator > 0 else 0.0\n",
    "\n",
    "        self.precision = safe_division(\n",
    "            sum([len(sample.true_positives) for sample in self.samples]),\n",
    "            sum([len(sample.predicted_entities) for sample in self.samples]),\n",
    "        )\n",
    "        self.recall = safe_division(\n",
    "            sum([len(sample.true_positives) for sample in self.samples]),\n",
    "            # TODO: Check that we can't predict the same entity twice\n",
    "            sum([len(sample.ground_truth_entities) for sample in self.samples]),\n",
    "        )\n",
    "        self.f1 = safe_division(2 * self.precision * self.recall, self.precision + self.recall)\n",
    "        self.precision_boe = safe_division(\n",
    "            sum([len(sample.true_positives_boe) for sample in self.samples]),\n",
    "            sum([len(sample.predicted_entities) for sample in self.samples]),\n",
    "        )\n",
    "        self.recall_boe = safe_division(\n",
    "            sum([len(sample.true_positives_boe) for sample in self.samples]),\n",
    "            sum([len(sample.ground_truth_entities) for sample in self.samples]),\n",
    "        )\n",
    "        self.f1_boe = safe_division(2 * self.precision_boe * self.recall_boe, self.precision_boe + self.recall_boe)\n",
    "        #return (f1, precision, recall), (f1_boe, precision_boe, recall_boe)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "235bcda9aabf5f8363267684c8e0d7a57e9fb12569fe58ae215aef35e2f0a58c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
