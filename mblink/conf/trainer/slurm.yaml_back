# @package _global_
#defaults:
#  - override /hydra/launcher: submitit_slurm

trainer:
  gpus: 8
  num_nodes: 1
  max_epochs: 25
  max_steps: null
  num_sanity_val_steps: 0
  log_every_n_steps: 10
  gradient_clip_val: 2.0
  accumulate_grad_batches: 1
  plugins: ddp_sharded
  strategy: ddp
  accelerator: gpu
  # precision: 16

hydra:
  launcher:
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    submitit_folder: ${hydra.sweep.dir}/.submitit/%j
    name: ${hydra.job.name}
    gpus_per_node: ${trainer.gpus}
    tasks_per_node: ${trainer.gpus}
    nodes: ${trainer.num_nodes}
    timeout_min: 1440
    cpus_per_task: 10
    mem_gb: null
    #    constraint: volta32gb
    partition: a100
    comment: null
    constraint: null
    exclude: null
    signal_delay_s: 120
    max_num_timeout: 0
    additional_parameters: {}
    array_parallelism: 256
  sweep:
    dir: /checkpoints/${env:USER}/hydra_outputs/${hydra.launcher.name}/${now:%Y-%m-%d-%H%M%S}
