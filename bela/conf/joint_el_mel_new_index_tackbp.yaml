defaults:
  - config
  - datamodule: joint_el_datamodule
  - task/transform: joint_el_xlmr_raw_transform_large
  - task/model: xlmr_large
  - task/optim: adamw
  - trainer: gpu_1_host

task:
  _target_: bela.task.joint_el_task.JointELTask
  only_train_disambiguation: false
  train_saliency: false
  embeddings_path: /fsx/movb/data/matcha/mel/embeddings_new.pt
  optim:
    lr: 3e-05
  use_gpu_index: true
  # disambiguation checkpoint
  load_from_checkpoint: "/checkpoints/movb/bela/2023-02-15-200343/0/lightning_logs/version_127953/checkpoints/checkpoint_best-v2.ckpt"
datamodule:
  train_path: /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/train_bela_format_all_languages.jsonl
  val_path: /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_all_languages.jsonl
  test_path: /fsx/louismartin/bela/retrieved_from_aws_backup/ndecao/TACKBP2015/dev_bela_format_all_languages.jsonl
  ent_catalogue_idx_path: /fsx/movb/data/matcha/mel/index_new.txt
  batch_size: 24

trainer:
  max_epochs: 10

checkpoint_callback:
    monitor: valid_f1